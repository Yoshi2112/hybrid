## PYTHON MODULES ##
from timeit import default_timer as timer
from scipy.interpolate import splrep, splev
import numpy as np
import numba as nb
import sys, os, pdb

Fu_override=False
do_parallel=True
nb.set_num_threads(4)         # Uncomment to manually set number of threads, otherwise will use all available

### PHYSICAL CONSTANTS ###
q   = 1.602177e-19                          # Elementary charge (C)
c   = 2.998925e+08                          # Speed of light (m/s)
mp  = 1.672622e-27                          # Mass of proton (kg)
me  = 9.109384e-31                          # Mass of electron (kg)
kB  = 1.380649e-23                          # Boltzmann's Constant (J/K)
e0  = 8.854188e-12                          # Epsilon naught - permittivity of free space
mu0 = (4e-7) * np.pi                        # Magnetic Permeability of Free Space (SI units)
RE  = 6.371e6                               # Earth radius in metres

#%% --- FUNCTIONS ---
#%% INITIALIZATION
@nb.njit()
def calc_losses(v_para, v_perp, B0x, st=0):
    '''
    For arrays of parallel and perpendicular velocities, finds the number and 
    indices of particles outside the loss cone.
    '''
    alpha        = np.arctan(v_perp / v_para)                   # Calculate particle PA's
    loss_cone    = np.arcsin(np.sqrt(B0x / B_A))                # Loss cone per particle (based on B0 at particle)
    
    in_loss_cone = np.zeros(v_para.shape[0], dtype=nb.int32)
    for ii in range(v_para.shape[0]):
        if np.abs(alpha[ii]) < loss_cone[ii]:                   # Determine if particle in loss cone
            in_loss_cone[ii] = 1
    
    N_loss       = in_loss_cone.sum()                           # Count number that are
    
    # Collect the indices of those in the loss cone
    loss_idx     = np.zeros(N_loss, dtype=nb.int32)
    lc           = 0
    for ii in range(v_para.shape[0]):
        if in_loss_cone[ii] == True:
            loss_idx[lc] = ii
            lc          += 1
        
    loss_idx    += st                                           # Offset indices to account for position in master array
    return N_loss, loss_idx


@nb.njit()
def LCD_by_rejection(pos, vel, sf_par, sf_per, st, en, jj):
    '''
    Takes in a Maxwellian or pseudo-maxwellian distribution. Removes any particles
    inside the loss cone and reinitializes them using the given scale factors 
    sf_par, sf_per (the thermal velocities).
    
    Is there a better way to do this with a Monte Carlo perhaps?
    '''
    B0x    = eval_B0x(pos[st: en])
    N_loss = 1

    while N_loss > 0:
        v_perp      = np.sqrt(vel[1, st: en] ** 2 + vel[2, st: en] ** 2)
        
        N_loss, loss_idx = calc_losses(vel[0, st: en], v_perp, B0x, st=st)

        # Catch for a particle on the boundary : Set 90 degree pitch angle (gyrophase shouldn't overly matter)
        if N_loss == 1:
            if abs(pos[loss_idx[0]]) == xmax:
                ww = loss_idx[0]
                vel[0, loss_idx[0]] = 0.
                vel[1, loss_idx[0]] = np.sqrt(vel[0, ww] ** 2 + vel[1, ww] ** 2 + vel[2, ww] ** 2)
                vel[2, loss_idx[0]] = 0.
                N_loss = 0

        if N_loss != 0:   
            new_vx = np.random.normal(0., sf_par, N_loss)             
            new_vy = np.random.normal(0., sf_per, N_loss)
            new_vz = np.random.normal(0., sf_per, N_loss)
            
            for ii in range(N_loss):
                vel[0, loss_idx[ii]] = new_vx[ii]
                vel[1, loss_idx[ii]] = new_vy[ii]
                vel[2, loss_idx[ii]] = new_vz[ii]
    return


def uniform_distribution():
    '''Creates an analytically uniform distribution of N numbers within each cell boundary

    INPUT:
        ppc       -- Number of particles per cell, per species

    OUTPUT:
        dist -- numpy ndarray containing numerical distribution
    '''
    dist = np.zeros(N)
    idx  = np.ones(N, dtype=np.uint8) * -1

    for jj in range(Nj):                    # For each species
        acc = 0
        idx[idx_start[jj]: idx_end[jj]] = jj
        
        for ii in range(NX):                # For each cell
            n_particles = nsp_ppc[jj]

            for kk in range(n_particles):   # For each particle in that cell
                dist[idx_start[jj] + acc + kk] = dx*(float(kk) / n_particles + ii)
            acc += n_particles
    dist -= NX*dx/2 
    return dist, idx


def gaussian_distribution():
    '''Creates an N-sampled normal distribution across all particle species within each simulation cell

    INPUT:
        N   -- Number of particles to distribute
        idx -- Index identifier for particle type : Correlates to parameters in part_params.py

    OUTPUT:
        dist -- Output distribution: Maxwellian, as generated by numpy's random.normal in 3 dimensions
    '''
    np.random.seed(seed)         # Random seed
    dist = np.zeros((3, N))      # Initialize array

    for jj in range(Nj):
        acc = 0                  # Species accumulator
        for ii in range(NX):
            n_particles = nsp_ppc[jj]
            dist[0, (idx_start[jj] + acc): ( idx_start[jj] + acc + n_particles)] = np.random.normal(0, np.sqrt((kB *  Tpar[ jj]) /  mass[jj]), n_particles) +  drift_v[jj]*va
            dist[1, (idx_start[jj] + acc): ( idx_start[jj] + acc + n_particles)] = np.random.normal(0, np.sqrt((kB *  Tperp[jj]) /  mass[jj]), n_particles)
            dist[2, (idx_start[jj] + acc): ( idx_start[jj] + acc + n_particles)] = np.random.normal(0, np.sqrt((kB *  Tperp[jj]) /  mass[jj]), n_particles)
            acc += n_particles

    return dist


def init_quiet_start():
    '''Creates an N-sampled normal distribution across all particle species within each simulation cell

    OUTPUT:
        pos -- 1xN array of particle positions. Pos[0] is uniformly distributed with boundaries depending on its temperature type
        vel -- 3xN array of particle velocities. Each component initialized as a Gaussian with a scale factor determined by the species perp/para temperature
        idx -- N   array of particle indexes, indicating which species it belongs to. Coded as an 8-bit signed integer, allowing values between +/-128
    
    New code: Removed all 3D position things because we won't need it for long. Check this later, since its easy to change
            Also removed all references to dist_type since initializing particles in the middle is stupid.
    '''
    pos = np.zeros(N, dtype=np.float64)
    vel = np.zeros((3, N), dtype=np.float64)
    idx = np.ones(N,       dtype=np.int8) * -1
    np.random.seed(seed)

    for jj in range(Nj):
        idx[idx_start[jj]: idx_end[jj]] = jj          # Set particle idx
        
        sf_par = np.sqrt(kB *  Tpar[ jj] /  mass[jj]) # Scale factors for velocity initialization
        sf_per = np.sqrt(kB *  Tperp[jj] /  mass[jj])
        
        half_n = nsp_ppc[jj] // 2                     # Half particles per cell - doubled later

        # Load particles in each applicable cell
        acc = 0; offset  = 0
        for ii in range(NX): 
            # Add particle if last cell (for symmetry, but only with open field boundaries)
            if ii == NX - 1 and field_periodic == 0:
                half_n += 1
                offset  = 1
                
            # Particle index ranges
            st = idx_start[jj] + acc
            en = idx_start[jj] + acc + half_n
            
            # Set position for half: Analytically uniform
            for kk in range(half_n):
                pos[st + kk] = dx*(float(kk) / (half_n - offset) + ii)
           
            # Turn [0, NC] distro into +/- NC/2 distro
            pos[st: en]-= 0.5*NX*dx
           
            # Set velocity for half: Randomly Maxwellian
            vel[0, st: en] = np.random.normal(0, sf_par, half_n)
            vel[1, st: en] = np.random.normal(0, sf_per, half_n)
            vel[2, st: en] = np.random.normal(0, sf_per, half_n)
            
            if homogenous == 0 and temp_type[jj] == 1:
                LCD_by_rejection(pos, vel, vth_par[jj], vth_perp[jj], st, en, jj)
               
            # Quiet start : Initialize other half
            pos[en: en + half_n] = pos[st: en]                      # Other half, same position
            vel[0, en: en + half_n] = vel[0, st: en] *  1.0         # Set parallel
            vel[1, en: en + half_n] = vel[1, st: en] * -1.0         # Invert perp velocities (v2 = -v1)
            vel[2, en: en + half_n] = vel[2, st: en] * -1.0
            
            vel[0, st: en + half_n] += drift_v[jj] * va             # Add drift offset
            
            acc                    += half_n * 2

    return pos, vel, idx


@nb.njit()
def set_damping_array(B_damping_array, DT):
    '''Create masking array for magnetic field damping used to apply open
    boundaries. Based on applcation by Shoji et al. (2011) and
    Umeda et al. (2001)
    '''
    r_damp   = np.sqrt(29.7 * 0.5 * va * (0.5 * DT / dx) / ND)   # Damping coefficient
    r_damp  *= damping_multiplier
    
    # Do B-damping array
    B_dist_from_mp  = np.abs(np.arange(NC + 1) - 0.5*NC)                # Distance of each B-node from midpoint
    for ii in range(NC + 1):
        if B_dist_from_mp[ii] > 0.5*NX:
            B_damping_array[ii] = 1. - r_damp * ((B_dist_from_mp[ii] - 0.5*NX) / ND) ** 2 
        else:
            B_damping_array[ii] = 1.0
    return


def set_timestep(vel):
    # NOTE: Can probably ease off on the ion_ts once I validate this 
    ion_ts   = dxm * orbit_res / gyfreq           # Timestep to resolve gyromotion
    vel_ts   = 0.5*dx / np.max(np.abs(vel[0, :])) # Timestep to satisfy CFL condition: Fastest particle doesn't traverse more than half a cell in one time step

    DT       = min(ion_ts, vel_ts)
    max_time = max_wcinv / gyfreq                 # Total runtime in seconds
    max_inc  = int(max_time / DT) + 1             # Total number of time steps
    
    if part_res == 0:
        part_save_iter = 1
    else:
        part_save_iter = int(part_res / (DT*gyfreq))

    if field_res == 0:
        field_save_iter = 1
    else:
        field_save_iter = int(field_res / (DT*gyfreq))

    print('Timestep: %.4fs, %d iterations total' % (DT, max_inc))
    
    if adaptive_subcycling == True:
        k_max      = np.pi / dx
        dispfreq   = (k_max ** 2) * B_xmax / (mu0 * ne * q)            # Dispersion frequency (units of k?)
        dt_sc      = freq_res / dispfreq
        subcycles  = int(DT / dt_sc + 1)
        print('Number of subcycles required: {}'.format(subcycles))
    else:
        subcycles = default_subcycles
        print('Number of subcycles set at default: {}'.format(subcycles))
    
    if save_fields == 1 or save_particles == 1:
        store_run_parameters(DT, part_save_iter, field_save_iter, max_inc, max_time, subcycles)
    
    B_damping_array = np.ones(NC + 1, dtype=float)
    set_damping_array(B_damping_array, DT)
    
    return DT, max_inc, part_save_iter, field_save_iter, subcycles, B_damping_array


#%% PARTICLES 
@nb.njit(parallel=do_parallel)
def assign_weighting_TSC(pos, I, W, E_nodes=True):
    '''Triangular-Shaped Cloud (TSC) weighting scheme used to distribute particle densities to
    nodes and interpolate field values to particle positions. Ref. Lipatov? Or Birdsall & Langdon?

    INPUT:
        pos     -- particle positions (x)
        I       -- Leftmost (to nearest) nodes. Output array
        W       -- TSC weights, 3xN array starting at respective I
        E_nodes -- True/False flag for calculating values at electric field
                   nodes (grid centres) or not (magnetic field, edges)
    
    The maths effectively converts a particle position into multiples of dx (i.e. nodes),
    rounded (to get nearest node) and then offset to account for E/B grid staggering and 
    to get the leftmost node. This is then offset by the damping number of nodes, ND. The
    calculation for weighting (dependent on delta_left).
    
    NOTE: The addition of `epsilon' prevents banker's rounding due to precision limits. This
          is the easiest way to get around it.
          
    NOTE2: If statements in weighting prevent double counting of particles on simulation
           boundaries. abs() with threshold used due to machine accuracy not recognising the
           upper boundary sometimes. Note sure how big I can make this and still have it
           be valid/not cause issues, but considering the scale of normal particle runs (speeds
           on the order of va) it should be plenty fine.
           
    Could vectorize this with the temp_N array, then check for particles on the boundaries (for
    manual setting)
    
    QUESTION :: Why do particles on the boundary only give 0.5 weighting? 
    ANSWER   :: It seems legit and prevents double counting of a particle on the boundary. Since it
                is a B-field node, there should be 0.5 weighted to both nearby E-nodes. In this case,
                reflection doesn't make sense because there cannot be another particle there - there is 
                only one midpoint position (c.f. mirroring contributions of all other particles due to 
                pretending there's another identical particle on the other side of the simulation boundary).
    
    UPDATE :: Periodic fields don't require weightings of 0.5 on the boundaries. Loop was copied without
               this option below because it prevents needing to evaluating field_periodic for every
               particle.
    '''
    Np         = pos.shape[0]
    epsil      = 1e-15
    
    if E_nodes == True:
        grid_offset   = 0.5
    else:
        grid_offset   = 0.0
    
    particle_transform = xmax + (ND - grid_offset)*dx  + epsil      # Offset to account for E/B grid and damping nodes
    
    if field_periodic == 0:
        for ii in nb.prange(Np):
            xp          = (pos[ii] + particle_transform) / dx       # Shift particle position >= 0
            I[ii]       = int(round(xp) - 1.0)                      # Get leftmost to nearest node (Vectorize?)
            delta_left  = I[ii] - xp                                # Distance from left node in grid units
            
            if abs(pos[ii] - xmin) < 1e-10:
                I[ii]    = ND - 1
                W[0, ii] = 0.0
                W[1, ii] = 0.5
                W[2, ii] = 0.0
            elif abs(pos[ii] - xmax) < 1e-10:
                I[ii]    = ND + NX - 1
                W[0, ii] = 0.5
                W[1, ii] = 0.0
                W[2, ii] = 0.0
            else:
                W[0, ii] = 0.5  * np.square(1.5 - abs(delta_left))  # Get weighting factors
                W[1, ii] = 0.75 - np.square(delta_left + 1.)
                W[2, ii] = 1.0  - W[0, ii] - W[1, ii]
    else:
        for ii in nb.prange(Np):
            xp          = (pos[ii] + particle_transform) / dx       # Shift particle position >= 0
            I[ii]       = int(round(xp) - 1.0)                      # Get leftmost to nearest node (Vectorize?)
            delta_left  = I[ii] - xp                                # Distance from left node in grid units

            W[0, ii] = 0.5  * np.square(1.5 - abs(delta_left))  # Get weighting factors
            W[1, ii] = 0.75 - np.square(delta_left + 1.)
            W[2, ii] = 1.0  - W[0, ii] - W[1, ii]
    return


@nb.njit(parallel=do_parallel)
def velocity_update(pos, vel, Ie, W_elec, Ib, W_mag, idx, B, E, dt):
    
    for ii in nb.prange(pos.shape[0]):
        if idx[ii] >= 0:
            # Calculate wave fields at particle position
            _Ep = np.zeros(3, dtype=np.float64)  
            _Bp = np.zeros(3, dtype=np.float64)
            
            for jj in nb.prange(3):
                for kk in nb.prange(3):
                    _Ep[kk] += E[Ie[ii] + jj, kk] * W_elec[jj, ii]   
                    _Bp[kk] += B[Ib[ii] + jj, kk] * W_mag[ jj, ii]   
    # =============================================================================
    #         Jp = J[Ie    , 0:3] * W_elec[0]                 \
    #            + J[Ie + 1, 0:3] * W_elec[1]                 \
    #            + J[Ie + 2, 0:3] * W_elec[2]                 # Current at particle location
    #            
    #         Ep -= (charge[idx] / q) * e_resis * Jp          # "Effective" E-field accounting for electron resistance
    # =============================================================================                
    
            # Start Boris Method
            qmi = 0.5 * dt * qm_ratios[idx[ii]]                             # q/m variable including dt
            
            # vel -> v_minus
            vel[0, ii] += qmi * _Ep[0]
            vel[1, ii] += qmi * _Ep[1]
            vel[2, ii] += qmi * _Ep[2]
            
            # Calculate background field at particle position (using v_minus)
            _Bp[0]   += B_eq * (1.0 + a * pos[ii] * pos[ii])
            constant  = a * B_eq
            l_cyc     = qm_ratios[idx[ii]] * _Bp[0]
            _Bp[1]   += constant * pos[ii] * vel[2, ii] / l_cyc
            _Bp[2]   -= constant * pos[ii] * vel[1, ii] / l_cyc
            T         = qmi * _Bp 
            S         = 2.*T / (1. + T[0]*T[0] + T[1]*T[1] + T[2]*T[2])
                
            # Calculate v_prime (maybe use a temp array here?)
            v_prime    = np.zeros(3, dtype=np.float64)
            v_prime[0] = vel[0, ii] + vel[1, ii] * T[2] - vel[2, ii] * T[1]
            v_prime[1] = vel[1, ii] + vel[2, ii] * T[0] - vel[0, ii] * T[2]
            v_prime[2] = vel[2, ii] + vel[0, ii] * T[1] - vel[1, ii] * T[0]
            
            # vel_minus -> vel_plus
            vel[0, ii] += v_prime[1] * S[2] - v_prime[2] * S[1]
            vel[1, ii] += v_prime[2] * S[0] - v_prime[0] * S[2]
            vel[2, ii] += v_prime[0] * S[1] - v_prime[1] * S[0]
            
            # vel_plus -> vel (updated)
            vel[0, ii] += qmi * _Ep[0]
            vel[1, ii] += qmi * _Ep[1]
            vel[2, ii] += qmi * _Ep[2]
    return


@nb.njit(parallel=do_parallel)
def position_update(pos, vel, idx, Ie, W_elec, DT):
    '''Updates the position of the particles using x = x0 + vt. 
    Also updates particle nearest node and weighting.
    '''
    for ii in nb.prange(pos.shape[0]):
        if idx[ii] > 0:
            pos[ii] += vel[0, ii] * DT
            
            # Check if particle has left simulation and apply boundary conditions
            if (pos[ii] < xmin or pos[ii] > xmax):
    
                if particle_periodic == 1:  
                    # Mario (Periodic)
                    if pos[ii] > xmax:
                        pos[ii] += xmin - xmax
                    elif pos[ii] < xmin:
                        pos[ii] += xmax - xmin 
                      
                elif particle_open == 1:                
                    # Open: Deactivate particles that leave the simulation space
                    pos[ii]     = 0.0
                    vel[0, ii]  = 0.0
                    vel[1, ii]  = 0.0
                    vel[2, ii]  = 0.0
                    idx[ii]     = -1
                                
                elif particle_reinit == 1: 
                    # Reinitialize vx based on flux distribution
                    vel[0, ii]  = generate_vx(vth_par[idx[ii]])
                    vel[0, ii] *= -np.sign(pos[ii])
                    
                    # Re-initialize v_perp and check pitch angle
                    if temp_type[idx[ii]] == 0 or homogenous == 1:
                        vel[1, ii] = np.random.normal(0, vth_perp[idx[ii]])
                        vel[2, ii] = np.random.normal(0, vth_perp[idx[ii]])
                    else:
                        particle_PA = 0.0
                        while np.abs(particle_PA) < loss_cone_xmax:
                            vel[1, ii]  = np.random.normal(0, vth_perp[idx[ii]])
                            vel[2, ii]  = np.random.normal(0, vth_perp[idx[ii]])
                            v_perp      = np.sqrt(vel[1, ii] ** 2 + vel[2, ii] ** 2)
                            
                            particle_PA = np.arctan(v_perp / vel[0, ii])
    
                    # Place back inside simulation domain
                    if pos[ii] < xmin:
                        pos[ii] = xmin + np.random.uniform(0, 1) * vel[0, ii] * DT
                    elif pos[ii] > xmax:
                        pos[ii] = xmax + np.random.uniform(0, 1) * vel[0, ii] * DT
                
                else:
                    # Reflect
                    if pos[ii] > xmax:
                        pos[ii] = 2*xmax - pos[ii]
                    elif pos[ii] < xmin:
                        pos[ii] = 2*xmin - pos[ii]
                        
                    vel[0, ii] *= -1.0
            
    assign_weighting_TSC(pos, Ie, W_elec)
    return


@nb.njit()
def inject_particles(pos, vel, idx, mp_flux, DT):        
    '''
    How to create new particles in parallel? Just test serial for now, but this
    might become my most expensive function for large N.
    
    Also need to work out how to add flux in serial (might just have to put it
    in calling function: advance_particles_and_moments())
    
    NOTE: How does this work for -0.5*DT ?? Might have to double check
    '''
    # Add flux at each boundary 
    for kk in range(2):
        mp_flux[kk, :] += inject_rate*DT
        
    # acc used only as placeholder to mark place in array. How to do efficiently? 
    acc = 0; n_created = 0
    for ii in nb.prange(2):
        for jj in nb.prange(Nj):
            N_inject = int(mp_flux[ii, jj] // 2)
            
            for xx in nb.prange(N_inject):
                
                # Find two empty particles (Yes clumsy coding but it works)
                for kk in nb.prange(acc, pos.shape[0]):
                    if idx[kk] < 0:
                        kk1 = kk
                        acc = kk + 1
                        break
                for kk in nb.prange(acc, pos.shape[0]):
                    if idx[kk] < 0:
                        kk2 = kk
                        acc = kk + 1
                        break

                # Reinitialize vx based on flux distribution
                vel[0, kk1] = generate_vx(vth_par[jj])
                idx[kk1]    = jj
                
                # Re-initialize v_perp and check pitch angle
                if temp_type[jj] == 0 or homogenous == True:
                    vel[1, kk1] = np.random.normal(0, vth_perp[jj])
                    vel[2, kk1] = np.random.normal(0, vth_perp[jj])
                else:
                    particle_PA = 0.0
                    while np.abs(particle_PA) <= loss_cone_xmax:
                        vel[1, kk1] = np.random.normal(0, vth_perp[jj])
                        vel[2, kk1] = np.random.normal(0, vth_perp[jj])
                        v_perp      = np.sqrt(vel[1, kk1] ** 2 + vel[2, kk1] ** 2)
                        particle_PA = np.arctan(v_perp / vel[0, kk1])
                
                # Amount travelled (vel always +ve at first)
                dpos = np.random.uniform(0, 1) * vel[0, kk1] * DT
                
                # Left boundary injection
                if ii == 0:
                    pos[kk1]    = xmin + dpos
                    vel[0, kk1] = np.abs(vel[0, kk1])
                    
                # Right boundary injection
                else:
                    pos[kk1]    = xmax - dpos
                    vel[0, kk1] = -np.abs(vel[0, kk1])
                
                # Copy values to second particle (Same position, xvel. Opposite v_perp) 
                idx[kk2]    = idx[kk1]
                pos[kk2]    = pos[kk1]
                vel[0, kk2] = vel[0, kk1]
                vel[1, kk2] = vel[1, kk1] * -1.0
                vel[2, kk2] = vel[2, kk1] * -1.0
                
                # Subtract new macroparticles from accrued flux
                mp_flux[ii, jj] -= 2.0
                n_created       += 2
    return


@nb.njit()
def vfx(vx, vth):
    f_vx  = np.exp(- 0.5 * (vx / vth) ** 2)
    f_vx /= vth * np.sqrt(2 * np.pi)
    return vx * f_vx


@nb.njit()
def generate_vx(vth):
    '''
    Maybe could try batch approach? If we need X number of solutions and we do
    batches of 100 or something and just pick the first x number. Then again,
    it depends on how long this has to loop until a valid value is found... if
    it only takes a few iterations, it's not worth it. But if it takes a few
    thousand to get sufficient numbers, then maybe it'll be worth it?
    '''
    while True:
        y_uni = np.random.uniform(0, 4*vth)
        Py    = vfx(y_uni, vth)
        x_uni = np.random.uniform(0, 0.25)
        if Py >= x_uni:
            return y_uni



#%% SOURCES
@nb.njit()
def push_current(J_in, J_out, E, B, B_center, L, G, dt):
    '''Uses an MHD-like equation to advance the current with a moment method as 
    per Matthews (1994) CAM-CL method. Fills in ghost cells at edges (excluding very last one)
    
    INPUT:
        J  -- Ionic current (J plus)
        E  -- Electric field
        B  -- Magnetic field (offset from E by 0.5dx)
        L  -- "Lambda" MHD variable
        G  -- "Gamma"  MHD variable
        dt -- Timestep
        
    OUTPUT:
        J_plus in main() becomes J_half (same memory space)
    '''
    J_out    *= 0
    
    G_cross_B = np.zeros(E.shape, dtype=np.float64)
    for ii in np.arange(NC):
        G_cross_B[ii, 0] = G[ii, 1] * B_center[ii, 2] - G[ii, 2] * B_center[ii, 1]
        G_cross_B[ii, 1] = G[ii, 2] * B_center[ii, 0] - G[ii, 0] * B_center[ii, 2]
        G_cross_B[ii, 2] = G[ii, 0] * B_center[ii, 1] - G[ii, 1] * B_center[ii, 0]
    
    for ii in range(3):
        J_out[:, ii] = J_in[:, ii] + 0.5*dt * (L * E[:, ii] + G_cross_B[:, ii]) 
    
    # Copy periodic values
    if field_periodic == 1:
        for ii in range(3):
            # Copy edge cells
            J_out[ro1, ii] = J_out[li1, ii]
            J_out[ro2, ii] = J_out[li2, ii]
            J_out[lo1, ii] = J_out[ri1, ii]
            J_out[lo2, ii] = J_out[ri2, ii]
            
            # Fill remaining ghost cells
            J_out[:lo2, ii] = J_out[lo2, ii]
            J_out[ro2:, ii] = J_out[ro2, ii]
    return


@nb.njit(parallel=False)
def deposit_both_moments(pos, vel, Ie, W_elec, idx, n_i, nu_i):
    '''Collect number and velocity moments in each cell, weighted by their distance
    from cell nodes.

    INPUT:
        pos    -- Particle positions (x)
        vel    -- Particle 3-velocities
        Ie     -- Particle leftmost to nearest E-node
        W_elec -- Particle TSC weighting across nearest, left, and right nodes
        idx    -- Particle species identifier

    OUTPUT:
        n_i    -- Species number moment array(size, Nj)
        nu_i   -- Species velocity moment array (size, Nj)
        
    Note: Parallel disabled for this and related functions because numba (as of
      23/02/2021) doesn't support parallel array reduction if the target is an
      array.
    '''    
    for ii in nb.prange(pos.shape[0]):
        I   = Ie[ ii]
        sp  = idx[ii]
        if sp >= 0:
            for kk in range(3):
                nu_i[I,     sp, kk] += W_elec[0, ii] * vel[kk, ii]
                nu_i[I + 1, sp, kk] += W_elec[1, ii] * vel[kk, ii]
                nu_i[I + 2, sp, kk] += W_elec[2, ii] * vel[kk, ii]
            
            n_i[I,     sp] += W_elec[0, ii]
            n_i[I + 1, sp] += W_elec[1, ii]
            n_i[I + 2, sp] += W_elec[2, ii]
    return


@nb.njit(parallel=False)
def deposit_velocity_moments(vel, Ie, W_elec, idx, nu_i):
    '''Collect velocity moment in each cell, weighted by their distance
    from cell nodes.

    INPUT:
        vel    -- Particle 3-velocities
        Ie     -- Particle leftmost to nearest E-node
        W_elec -- Particle TSC weighting across nearest, left, and right nodes
        idx    -- Particle species identifier
        
    OUTPUT:
        nu_i   -- Species velocity moment array (size, Nj)
    '''
    for ii in nb.prange(vel.shape[1]):
        I   = Ie[ ii]
        sp  = idx[ii]
        
        if sp >= 0:
            for kk in range(3):
                nu_i[I,     sp, kk] += W_elec[0, ii] * vel[kk, ii]
                nu_i[I + 1, sp, kk] += W_elec[1, ii] * vel[kk, ii]
                nu_i[I + 2, sp, kk] += W_elec[2, ii] * vel[kk, ii]
    return


@nb.njit()
def manage_source_term_boundaries(arr):
    '''
    If numba doesn't like the different possible shapes of arr
    just use a loop in the calling function to work each component 
    and this becomes for 1D arrays only
    
    DOUBLE CHECK THIS AT SOME POINT
    '''
    if field_periodic == 0:
        arr[ND]          += arr[ND - 1]
        arr[ND + NX - 1] += arr[ND + NX]
    else:
        # If periodic, move contributions
        arr[li1] += arr[ro1]
        arr[li2] += arr[ro2]
        arr[ri1] += arr[lo1]
        arr[ri2] += arr[lo2]
        
        # ...and copy periodic values
        arr[ro1] = arr[li1]
        arr[ro2] = arr[li2]
        arr[lo1] = arr[ri1]
        arr[lo2] = arr[ri2]
        
        # ...and Fill remaining ghost cells
        arr[:lo2] = arr[lo2]
        arr[ro2:] = arr[ro2]
    return


@nb.njit()
def init_collect_moments(pos, vel, Ie, W_elec, idx, ni_init, nu_init, ni, nu_plus, 
                         rho_0, rho, J_init, J_plus, L, G, dt):
    '''Moment collection and position advance function. Specifically used at initialization or
    after timestep synchronization.

    INPUT:
        pos    -- Particle positions (x)
        vel    -- Particle 3-velocities
        Ie     -- Particle leftmost to nearest E-node
        W_elec -- Particle TSC weighting across nearest, left, and right nodes
        idx    -- Particle species identifier
        DT     -- Timestep for position advance
        
    OUTPUT:
        pos     -- Advanced particle positions
        Ie      -- Updated leftmost to nearest E-nodes
        W_elec  -- Updated TSC weighting coefficients
        rho_0   -- Charge  density at initial time (p0)
        rho     -- Charge  density at +0.5 timestep
        J_init  -- Current density at initial time (J0)
        J_plus  -- Current density at +0.5 timestep
        G       -- "Gamma"  MHD variable for current advance : Current-like
        L       -- "Lambda" MHD variable for current advance :  Charge-like
    '''
    ni      *= 0.0
    ni_init *= 0.0
    rho_0   *= 0.0
    rho     *= 0.0
    nu_init *= 0.0
    nu_plus *= 0.0
    J_init  *= 0.0
    J_plus  *= 0.0
    L       *= 0.0
    G       *= 0.0
                         
    deposit_both_moments(pos, vel, Ie, W_elec, idx, ni_init, nu_init)      # Collects sim_particles/cell/species
    position_update(pos, vel, idx, Ie, W_elec, dt)
    #inject_particles(pos, vel, idx, mp_flux, dt)
    deposit_both_moments(pos, vel, Ie, W_elec, idx, ni, nu_plus)

    if source_smoothing == 1:
        for jj in range(Nj):
            ni[:, jj]  = smooth(ni[:, jj])
        
            for kk in range(3):
                nu_plus[:, jj, kk] = smooth(nu_plus[:,  jj, kk])
                nu_init[:, jj, kk] = smooth(nu_init[:, jj, kk])
    
    # Sum contributions across species
    for jj in range(Nj):
        rho_0   += ni_init[:, jj]   * n_contr[jj] * charge[jj]
        rho     += ni[:, jj]        * n_contr[jj] * charge[jj]
        L       += ni[:, jj]        * n_contr[jj] * charge[jj] ** 2 / mass[jj]
        
        for kk in range(3):
            J_init[:, kk]  += nu_init[:, jj, kk] * n_contr[jj] * charge[jj]
            J_plus[ :, kk] += nu_plus[:, jj, kk] * n_contr[jj] * charge[jj]
            G[      :, kk] += nu_plus[:, jj, kk] * n_contr[jj] * charge[jj] ** 2 / mass[jj]

    manage_source_term_boundaries(rho_0)
    manage_source_term_boundaries(rho)
    manage_source_term_boundaries(L)
    for ii in range(3):
        manage_source_term_boundaries(J_init[:, ii])
        manage_source_term_boundaries(J_plus[:, ii])
        manage_source_term_boundaries(G[:, ii])

    for ii in range(rho_0.shape[0]):
        if rho_0[ii] < min_dens * ne * q:
            rho_0[ii] = min_dens * ne * q
            
        if rho[ii] < min_dens * ne * q:
            rho[ii] = min_dens * ne * q
    return


@nb.njit()
def collect_moments(pos, vel, Ie, W_elec, idx, ni, nu_plus, nu_minus, 
                         rho, J_minus, J_plus, L, G, dt):
    '''
    Moment collection and position advance function.

    INPUT:
        pos    -- Particle positions (x)
        vel    -- Particle 3-velocities
        Ie     -- Particle leftmost to nearest E-node
        W_elec -- Particle TSC weighting across nearest, left, and right nodes
        idx    -- Particle species identifier
        DT     -- Timestep for position advance
        
    OUTPUT:
        pos     -- Advanced particle positions
        Ie      -- Updated leftmost to nearest E-nodes
        W_elec  -- Updated TSC weighting coefficients
        rho     -- Charge  density at +0.5 timestep
        J_plus  -- Current density at +0.5 timestep
        J_minus -- Current density at initial time (J0)
        G       -- "Gamma"  MHD variable for current advance
        L       -- "Lambda" MHD variable for current advance    
    '''
    ni       *= 0.0
    rho      *= 0.0
    nu_minus *= 0.0
    nu_plus  *= 0.0
    J_minus  *= 0.0
    J_plus   *= 0.0
    L        *= 0.0
    G        *= 0.0
    
    deposit_velocity_moments(vel, Ie, W_elec, idx, nu_minus)
    position_update(pos, vel, idx, Ie, W_elec, dt)
    #inject_particles(pos, vel, idx, mp_flux, dt)
    deposit_both_moments(pos, vel, Ie, W_elec, idx, ni, nu_plus)
    
    if source_smoothing == 1:
        for jj in range(Nj):
            ni[:, jj]  = smooth(ni[:, jj])
        
            for kk in range(3):
                nu_plus[ :, jj, kk] = smooth(nu_plus[:,  jj, kk])
                nu_minus[:, jj, kk] = smooth(nu_minus[:, jj, kk])
    
    for jj in range(Nj):
        rho  += ni[:, jj] * n_contr[jj] * charge[jj]
        L    += ni[:, jj] * n_contr[jj] * charge[jj] ** 2 / mass[jj]
        
        for kk in range(3):
            J_minus[:, kk] += nu_minus[:, jj, kk] * n_contr[jj] * charge[jj]
            J_plus[ :, kk] += nu_plus[ :, jj, kk] * n_contr[jj] * charge[jj]
            G[      :, kk] += nu_plus[ :, jj, kk] * n_contr[jj] * charge[jj] ** 2 / mass[jj]
        
    manage_source_term_boundaries(rho)
    manage_source_term_boundaries(L)
    for ii in range(3):
        manage_source_term_boundaries(J_minus[:, ii])
        manage_source_term_boundaries(J_plus[:, ii])
        manage_source_term_boundaries(G[:, ii])
        
    for ii in range(rho.shape[0]):
        if rho[ii] < min_dens * ne * q:
            rho[ii] = min_dens * ne * q  
    return


@nb.njit()
def smooth(function):
    '''
    Smoothing function: Applies Gaussian smoothing routine across adjacent cells. 
    Assummes no contribution from ghost cells.
    '''
    size         = function.shape[0]
    new_function = np.zeros(size, dtype=np.float64)

    for ii in np.arange(1, size - 1):
        new_function[ii - 1] = 0.25*function[ii] + new_function[ii - 1]
        new_function[ii]     = 0.50*function[ii] + new_function[ii]
        new_function[ii + 1] = 0.25*function[ii] + new_function[ii + 1]

    # Move Ghost Cell Contributions: Periodic Boundary Condition
    new_function[1]        += new_function[size - 1]
    new_function[size - 2] += new_function[0]

    # Set ghost cell values to mirror corresponding real cell
    new_function[0]        = new_function[size - 2]
    new_function[size - 1] = new_function[1]
    return new_function


#%% FIELDS
@nb.njit()
def eval_B0x(x):
    return B_eq * (1. + a * x**2)


@nb.njit()
def get_curl_B(B):
    ''' Returns a vector quantity for the curl of a field valid at the positions 
    between its gridpoints (i.e. curl(B) -> E-grid, etc.)
    
    INPUT:
        field    -- The 3D field to take the curl of
        DX       -- Spacing between the nodes, mostly for diagnostics. 
                    Defaults to grid spacing specified at initialization.
                 
    OUTPUT:
        curl  -- Finite-differenced solution for the curl of the input field.
        
    NOTE: This function will only work with this specific 1D hybrid code due to both 
          E and B fields having the same number of nodes (due to TSC weighting) and
         the lack of derivatives in y, z
    '''
    curlB = np.zeros((NC, 3), dtype=nb.float64)
    for ii in nb.prange(B.shape[0] - 1):
        curlB[ii, 1] = - (B[ii + 1, 2] - B[ii, 2])
        curlB[ii, 2] =    B[ii + 1, 1] - B[ii, 1]
    return curlB/(dx*mu0)


@nb.njit()
def get_curl_E(_E, dE):
    ''' 
    Returns a vector quantity for the curl of a field valid at the positions 
    between its gridpoints (i.e. curl(E) -> B-grid, etc.)
    
    INPUT:
        field    -- The 3D field to take the curl of
        DX       -- Spacing between the nodes, mostly for diagnostics. 
                    Defaults to grid spacing specified at initialization.
                 
    OUTPUT:
        curl  -- Finite-differenced solution for the curl of the input field.
    '''   
    dE *= 0.
    for ii in np.arange(1, _E.shape[0]):
        dE[ii, 1] = - (_E[ii, 2] - _E[ii - 1, 2])
        dE[ii, 2] =    _E[ii, 1] - _E[ii - 1, 1]
        
    # Curl at E[0] : Forward/Backward difference (stored in B[0]/B[NC])
    dE[0, 1] = -(-3*_E[0, 2] + 4*_E[1, 2] - _E[2, 2]) / 2
    dE[0, 2] =  (-3*_E[0, 1] + 4*_E[1, 1] - _E[2, 1]) / 2
    
    dE[NC, 1] = -(3*_E[NC - 1, 2] - 4*_E[NC - 2, 2] + _E[NC - 3, 2]) / 2
    dE[NC, 2] =  (3*_E[NC - 1, 1] - 4*_E[NC - 2, 1] + _E[NC - 3, 1]) / 2
    
    # Linearly extrapolate to endpoints
    dE[0, 1]      -= 2*(dE[1, 1] - dE[0, 1])
    dE[0, 2]      -= 2*(dE[1, 2] - dE[0, 2])
    
    dE[NC, 1]     += 2*(dE[NC, 1] - dE[NC - 1, 1])
    dE[NC, 2]     += 2*(dE[NC, 2] - dE[NC - 1, 2])

    dE /= dx
    return


@nb.njit()
def get_electron_temp(qn):
    '''
    Calculate the electron temperature in each cell. Depends on the charge density of each cell
    and the treatment of electrons: i.e. isothermal (ie=0) or adiabatic (ie=1)
    '''
    if ie == 0:
        te      = np.ones(qn.shape[0]) * Te0
    elif ie == 1:
        gamma_e = 5./3. - 1.
        te      = Te0 * np.power(qn / (q*ne), gamma_e)
    return te


@nb.njit()
def get_grad_P(qn, te):
    '''
    Returns the electron pressure gradient (in 1D) on the E-field grid using P = nkT and 
    finite difference.
    
    INPUT:
        qn -- Grid charge density
        te -- Grid electron temperature
        DX -- Grid separation, used for diagnostic purposes. Defaults to simulation dx.
        inter_type -- Linear (0) or cubic spline (1) interpolation.
        
    NOTE: Interpolation is needed because the finite differencing causes the result to be deposited on the 
    B-grid. Moving it back to the E-grid requires an interpolation. Cubic spline is desired due to its smooth
    derivatives and its higher order weighting (without the polynomial craziness)
    '''
    grad_pe_B     = np.zeros(NC + 1, dtype=np.float64)
    grad_P        = np.zeros(NC    , dtype=np.float64)
    Pe            = qn * kB * te / q

    # Center points
    for ii in np.arange(1, qn.shape[0]):
        grad_pe_B[ii] = (Pe[ii] - Pe[ii - 1])
            
    # Set endpoints (there should be no gradients here anyway, but just to be safe)
    grad_pe_B[0]  = grad_pe_B[1]
    grad_pe_B[NC] = grad_pe_B[NC - 1]
        
    # Re-interpolate to E-grid
    grad_P = interpolate_edges_to_center_1D(grad_pe_B)/dx
    return Pe, grad_P


@nb.njit()
def get_grad_P_alt(qn, te):
    '''
    Returns the electron pressure gradient (in 1D) on the E-field grid using P = nkT and 
    finite difference.
     
    INPUT:
        qn     -- Grid charge density
        te     -- Grid electron temperature
        grad_P -- Output array for electron pressure gradient
        temp   -- intermediary array used to store electron pressure, since both
                  density and temperature may vary (with adiabatic approx.)
        
    Forwards/backwards differencing at the simulation cells at the edge of the
    physical space domain.
    
    Maybe check this at some point, or steal the one from the CAM_CL code.
    '''
    grad_P = np.zeros(NC    , dtype=np.float64)
    Pe     = qn * kB * te / q       # Store Pe in grad_P array for calculation

    # Central differencing, internal points
    for ii in nb.prange(1, NC - 1):
        grad_P[ii] = (Pe[ii + 1] - Pe[ii - 1])
        
    # Set endpoints (there should be no gradients here anyway, but just to be safe)
    grad_P[0]    = grad_P[1]
    grad_P[NC-1] = grad_P[NC - 2]

    grad_P    /= (2*dx)
    return Pe, grad_P


@nb.njit()
def get_grad_P_alt2(qn, te):
    '''
    Returns the electron pressure gradient (in 1D) on the E-field grid using P = nkT and 
    finite difference.
     
    INPUT:
        qn     -- Grid charge density
        te     -- Grid electron temperature
        grad_P -- Output array for electron pressure gradient
        temp   -- intermediary array used to store electron pressure, since both
                  density and temperature may vary (with adiabatic approx.)
        
    Forwards/backwards differencing at the simulation cells at the edge of the
    physical space domain.
    
    Maybe check this at some point, or steal the one from the CAM_CL code.
    '''
    grad_P = np.zeros(NC    , dtype=np.float64)
    Pe     = qn * kB * te / q       # Store Pe in grad_P array for calculation

    # Central differencing, internal points
    for ii in nb.prange(1, NC - 1):
        dpc = (qn[ii + 1] - qn[ii - 1])
        dTe = (te[ii + 1] - te[ii - 1])
        grad_P[ii] = (kB / (q*2*dx)) * (te[ii]*dpc + qn[ii]*dTe)
        
    # Set endpoints (there should be no gradients here anyway, but just to be safe)
    grad_P[0]  = grad_P[1]
    grad_P[NC-1] = grad_P[NC - 2]
    return Pe, grad_P


def get_grad_P_alt3(qn, te):
    '''
    Returns the electron pressure gradient (in 1D) on the E-field grid using P = nkT and 
    finite difference.
    
    INPUT:
        qn -- Grid charge density
        te -- Grid electron temperature
        DX -- Grid separation, used for diagnostic purposes. Defaults to simulation dx.
        inter_type -- Linear (0) or cubic spline (1) interpolation.
        
    NOTE: Interpolation is needed because the finite differencing causes the result to be deposited on the 
    B-grid. Moving it back to the E-grid requires an interpolation. Cubic spline is desired due to its smooth
    derivatives and its higher order weighting (without the polynomial craziness)
    '''
    grad_pe_B     = np.zeros(NC + 1, dtype=np.float64)
    Pe            = qn * kB * te / q

    # Center points
    for ii in np.arange(1, qn.shape[0]):
        grad_pe_B[ii] = (Pe[ii] - Pe[ii - 1])/dx
            
    # Set endpoints (there should be no gradients here anyway, but just to be safe)
    grad_pe_B[0]  = grad_pe_B[1]
    grad_pe_B[NC] = grad_pe_B[NC - 1]
        
    # Re-interpolate to E-grid
    coeffs = splrep(B_nodes, grad_pe_B)
    grad_P = splev( E_nodes, coeffs)
    return Pe, grad_P


@nb.njit()
def interpolate_edges_to_center_1D(grad_P, zero_boundaries=True):
    ''' 
    Same as 3D version just rejigged because its used for the grad_P calculation
    to take grad_P from the B-grid (because of the central difference) and put
    it back on the E-grid
    '''
    y2      = np.zeros((NC + 1), dtype=np.float64)
    interp  = np.zeros((NC    ), dtype=np.float64)
    
    # Calculate second derivative       
    # Interior B-nodes, Centered difference
    for ii in range(1, NC):
        y2[ii] = grad_P[ii + 1] - 2*grad_P[ii] + grad_P[ii - 1]
            
    # Edge B-nodes, Forwards/Backwards difference
    if zero_boundaries == True:
        y2[0 ] = 0.
        y2[NC] = 0.
    else:
        y2[0]  = 2*grad_P[0 ] - 5*grad_P[1     ] + 4*grad_P[2     ] - grad_P[3     ]
        y2[NC] = 2*grad_P[NC] - 5*grad_P[NC - 1] + 4*grad_P[NC - 2] - grad_P[NC - 3]
        
    # Do spline interpolation: E[ii] node is bracketed by B[ii], B[ii + 1] nodes
    for ii in range(NC):
        interp[ii] = 0.5 * (grad_P[ii] + grad_P[ii + 1] + (1/6) * (y2[ii] + y2[ii + 1]))
    return interp


@nb.njit()
def apply_boundary(_B, _damp):
    if field_periodic == 0:
        for ii in nb.prange(1, _B.shape[1]):
            _B[:, ii] *= _damp
    else:
        for ii in nb.prange(1, _B.shape[1]):
            # Boundary value (should be equal)
            end_bit = 0.5 * (_B[ND, ii] + _B[ND + NX, ii])

            _B[ND,      ii] = end_bit
            _B[ND + NX, ii] = end_bit
            
            _B[ND - 1, ii]  = _B[ND + NX - 1, ii]
            _B[ND - 2, ii]  = _B[ND + NX - 2, ii]
            
            _B[ND + NX + 1, ii] = _B[ND + 1, ii]
            _B[ND + NX + 2, ii] = _B[ND + 2, ii]
    return


#@nb.njit()
def cyclic_leapfrog(B1, B2, B_center, rho, J, curl, DT, subcycles, B_damping_array):
    '''
    Solves for the magnetic field push by keeping two copies and subcycling between them,
    averaging them at the end of the cycle as per Matthews (1994). The source terms are
    unchanged during the subcycle step. This method damps the high frequency dispersion 
    inherent in explicit hybrid simulations.
    
    INPUT:
        B1    -- Magnetic field to update (return value comes through here)
        B2    -- Empty array for second copy
        rho_i -- Total ion charge density
        J_i   -- Total ionic current density
        DT    -- Master simulation timestep. This function advances the field by 0.5*DT
        subcycles -- The number of subcycle steps to be performed. 
        
    22/02/2021 :: Applied damping field to each subcycle. Does this damping array
            need to account for subcycling in the DX/DT bit? Test later.
    '''
    H     = 0.5 * DT
    dh    = H / subcycles
    B2[:] = B1[:]

    ## DESYNC SECOND FIELD COPY - PUSH BY DH ##
    E, Ve, Te = calculate_E(B1, B_center, J, rho)
    get_curl_E(E, curl) 
    B2       -= dh * curl
    apply_boundary(B2, B_damping_array)
    get_B_cent(B2, B_center)

    ## RETURN IF NO SUBCYCLES REQUIRED ##
    if subcycles == 1:
        B1[:] = B2[:]
        return 

    ## MAIN SUBCYCLE LOOP ##
    for ii in range(subcycles - 1):             
        if ii%2 == 0:
            E, Ve, Te = calculate_E(B2, B_center, J, rho)
            get_curl_E(E, curl) 
            B1  -= 2 * dh * curl
            apply_boundary(B1, B_damping_array)
            get_B_cent(B1, B_center)
        else:
            E, Ve, Te = calculate_E(B1, B_center, J, rho)
            get_curl_E(E, curl) 
            B2  -= 2 * dh * curl
            apply_boundary(B2, B_damping_array)
            get_B_cent(B2, B_center)
            
    ## RESYNC FIELD COPIES ##
    if ii%2 == 0:
        E, Ve, Te = calculate_E(B2, B_center, J, rho)
        get_curl_E(E, curl) 
        B2  -= dh * curl
        apply_boundary(B2, B_damping_array)
        get_B_cent(B2, B_center)
    else:
        E, Ve, Te = calculate_E(B1, B_center, J, rho)
        get_curl_E(E, curl) 
        B1  -= dh * curl
        apply_boundary(B1, B_damping_array)
        get_B_cent(B1, B_center)

    ## AVERAGE FIELD SOLUTIONS: COULD PERFORM A CONVERGENCE TEST HERE IN FUTURE ##
    B1 += B2; B1 /= 2.0
    return


@nb.njit()
def add_J_ext(sim_time):
    '''
    Driven J designed as energy input into simulation. All parameters specified
    in the simulation_parameters script/file
    
    Designed as a Gaussian pulse so that things don't freak out by rising too 
    quickly. Just test with one source point at first
    
    NEED TO ADJUST SIM_TIME TO ACCOUNT FOR SUBCYCLING -- NOT YET DONE
    PROBABLY JUST NEED TO PASS A TIME ARGUMENT AROUND THE FIELD FUNCTIONS
    TO KEEP TRACK OF WHAT POINT IN TIME IT IS
    '''
    # Soft source wave (What t corresponds to this?)
    # Should put some sort of ramp on it?
    # Also needs to be polarised. By or Bz lagging/leading?
    J_ext = np.zeros((NC, 3), dtype=np.float64)
    phase = -90
    N_eq  = ND + NX//2
    time  = sim_time
    
    gaussian = np.exp(- ((time - pulse_offset)/ pulse_width) ** 2 )

    # Set new field values in array as soft source
    J_ext[N_eq, 1] = driven_ampl * gaussian*np.sin(2 * np.pi * driven_freq * time)
    J_ext[N_eq, 2] = driven_ampl * gaussian*np.sin(2 * np.pi * driven_freq * time + phase * np.pi / 180.)    
    return J_ext


@nb.njit()
def add_J_ext_pol(sim_time):
    '''
    Driven J designed as energy input into simulation. All parameters specified
    in the simulation_parameters script/file
    
    Designed as a Gaussian pulse so that things don't freak out by rising too 
    quickly. Just test with one source point at first
    
    Polarised with a LH mode only, uses five points with both w, k specified
    -- Not quite sure how to code this... do you just add a time delay (td, i.e. phase)
        to both the envelope and sin values at each point? 
        
    -- Source node as td=0, other nodes have td depending on distance from source, 
        (ii*dx) and the wave phase velocity v_ph = w/k (which are both known)
    
    P.S. A bunch of these values could be put in the simulation_parameters script.
    Optimize later (after testing shows that it actually works!)
    '''
    # Soft source wave (What t corresponds to this?)
    # Should put some sort of ramp on it?
    # Also needs to be polarised. By or Bz lagging/leading?
    J_ext = np.zeros((NC, 3), dtype=np.float64)
    phase = -np.pi / 2
    N_eq  = ND + NX//2
    time  = sim_time
    v_ph  = driven_freq / driven_k
    
    for off in np.arange(-2, 3):
        delay = off*dx / v_ph
        gauss = driven_ampl * np.exp(- ((time - pulse_offset - delay)/ pulse_width) ** 2 )
        
        J_ext[N_eq + off, 1] += gauss * np.sin(2 * np.pi * driven_freq * (time - delay))
        J_ext[N_eq + off, 2] += gauss * np.sin(2 * np.pi * driven_freq * (time - delay) + phase)    
    return J_ext


#@nb.njit()
def calculate_E(B, B_center, J, qn):
    '''Calculates the value of the electric field based on source term and magnetic field contributions, assuming constant
    electron temperature across simulation grid. This is done via a reworking of Ampere's Law that assumes quasineutrality,
    and removes the requirement to calculate the electron current. Based on equation 10 of Buchner (2003, p. 140).
    INPUT:
        B   -- Magnetic field array. Displaced from E-field array by half a spatial step.
        J   -- Ion current density. Source term, based on particle velocities
        qn  -- Charge density. Source term, based on particle positions
    OUTPUT:
        E_out -- Updated electric field array
    '''
    curlB    = get_curl_B(B)
    
    if pol_wave == 0:
        pass
    elif pol_wave == 1:
        add_J_ext()
    elif pol_wave == 2:
        add_J_ext_pol()
       
    Ve       = np.zeros((J.shape[0], 3), dtype=np.float64) 
    Ve[:, 0] = (J[:, 0] - curlB[:, 0]) / qn
    Ve[:, 1] = (J[:, 1] - curlB[:, 1]) / qn
    Ve[:, 2] = (J[:, 2] - curlB[:, 2]) / qn
    
    Te       = get_electron_temp(qn)
    Pe, del_p= get_grad_P_alt3(qn, Te)
    
    VexB     = np.zeros((NC, 3), dtype=np.float64)  
    for ii in np.arange(NC):
        VexB[ii, 0] = Ve[ii, 1] * B_center[ii, 2] - Ve[ii, 2] * B_center[ii, 1]
        VexB[ii, 1] = Ve[ii, 2] * B_center[ii, 0] - Ve[ii, 0] * B_center[ii, 2]
        VexB[ii, 2] = Ve[ii, 0] * B_center[ii, 1] - Ve[ii, 1] * B_center[ii, 0]

    E_out        = np.zeros((J.shape[0], 3), dtype=np.float64)                 
    E_out[:, 0]  = - VexB[:, 0] - del_p / qn
    E_out[:, 1]  = - VexB[:, 1]
    E_out[:, 2]  = - VexB[:, 2]

    E_out       += e_resis * J
    
    # Copy periodic values
    if field_periodic == 1:
        for ii in range(3):
            # Copy edge cells
            E_out[ro1, ii] = E_out[li1, ii]
            E_out[ro2, ii] = E_out[li2, ii]
            E_out[lo1, ii] = E_out[ri1, ii]
            E_out[lo2, ii] = E_out[ri2, ii]
            
            # Fill remaining ghost cells
            E_out[:lo2, ii] = E_out[lo2, ii]
            E_out[ro2:, ii] = E_out[ro2, ii]
            
    # Diagnostic flag for testing
    if disable_waves == 1:   
        E_out *= 0.
    
    return E_out, Ve, Te


#%% AUXILLIARY FUNCTIONS
# =============================================================================
# @nb.njit()
# def get_B_at_center(B, zero_boundaries=True):
#     ''' 
#     Used for interpolating values on the B-grid to the E-grid (for E-field calculation)
#     with a 3D array (e.g. B). Second derivative y2 is calculated on the B-grid, with
#     forwards/backwards difference used for endpoints. (i.e. y2 at data points)
#     
#     interp has one more gridpoint than required just because of the array used. interp[-1]
#     should remain zero.
#     
#     This might be able to be done without the intermediate y2 array since the interpolated
#     points don't require previous point values.
#     
#     As long as B-grid is filled properly in the push_B() routine, this shouldn't have to
#     vary for homogenous boundary conditions
#     
#     ADDS B0 TO X-AXIS ON TOP OF INTERPOLATION
#     '''
#     y2      = np.zeros((NC + 1, 3), dtype=np.float64)
#     interp  = np.zeros((NC    , 3), dtype=np.float64)
#     
#     # Calculate second derivative
#     for jj in range(1, B.shape[1]):
#         
#         # Interior B-nodes, Centered difference
#         for ii in range(1, NC):
#             y2[ii, jj] = B[ii + 1, jj] - 2*B[ii, jj] + B[ii - 1, jj]
#                 
#         # Edge B-nodes, Forwards/Backwards difference
#         if zero_boundaries == True:
#             y2[0 , jj] = 0.
#             y2[NC, jj] = 0.
#         else:
#             y2[0,  jj] = 2*B[0 ,    jj] - 5*B[1     , jj] + 4*B[2     , jj] - B[3     , jj]
#             y2[NC, jj] = 2*B[NC,    jj] - 5*B[NC - 1, jj] + 4*B[NC - 2, jj] - B[NC - 3, jj]
#         
#     # Do spline interpolation: E[ii] is bracketed by B[ii], B[ii + 1]
#     for jj in range(1, B.shape[1]):
#         for ii in range(NC):
#             interp[ii, jj] = 0.5 * (B[ii, jj] + B[ii + 1, jj] + (1/6) * (y2[ii, jj] + y2[ii + 1, jj]))
#     
#     # Add B0x to interpolated array
#     for ii in range(NC):
#         interp[ii, 0] = eval_B0x(E_nodes[ii])
#     return interp
# =============================================================================


def get_B_cent(_B, _B_cent):
    '''
    Quick and easy function to calculate B on the E-grid using scipy's cubic
    spline interpolation (mine seems to be broken). Could probably make this 
    myself and more efficient later, but need to eliminate problems!
    '''
    _B_cent *= 0.0
    for jj in range(1, 3):
        coeffs         = splrep(B_nodes, _B[:, jj])
        _B_cent[:, jj] = splev( E_nodes, coeffs)
    _B_cent[:, 0] = eval_B0x(E_nodes)
    return


#@nb.njit()
def check_timestep(qq, DT, pos, vel, Ie, W_elec, B, B_center, E, dns, 
                   max_inc, part_save_iter, field_save_iter, subcycles):
    max_Vx          = np.abs(vel[0, :]).max()
    max_V           = np.abs(vel      ).max()

    B_tot           = np.sqrt(B_center[:, 0] ** 2 + B_center[:, 1] ** 2 + B_center[:, 2] ** 2)
    high_rat        = qm_ratios.max()
    
    local_gyfreq    = high_rat  * np.abs(B_tot).max()      
    ion_ts          = orbit_res / local_gyfreq
    
    if E.max() != 0:
        elecfreq    = high_rat * (np.abs(E[:, 0] / max_V)).max()
        freq_ts     = freq_res / elecfreq                            
    else:
        freq_ts     = ion_ts
    
    vel_ts          = 0.75*dx / max_Vx
    DT_part         = min(freq_ts, vel_ts, ion_ts)
    
    # Reduce timestep
    change_flag       = 0
    if DT_part < 0.9*DT:
        position_update(pos, vel, idx, Ie, W_elec, -0.5*DT)
        
        change_flag      = 1
        DT              *= 0.5
        max_inc         *= 2
        qq              *= 2
        part_save_iter  *= 2
        field_save_iter *= 2
        print('Timestep halved. Syncing particle velocity/position with DT =', DT)
    
    # Increase timestep
    # DISABLED until I work out how to do the injection for half a timestep when this changes
    elif False and DT_part >= 4.0*DT and qq%2 == 0 and part_save_iter%2 == 0 and field_save_iter%2 == 0 and max_inc%2 == 0:
        position_update(pos, vel, idx, Ie, W_elec, -0.5*DT)
        
        change_flag       = 1
        DT               *= 2.0
        max_inc         //= 2
        qq              //= 2
        part_save_iter  //= 2
        field_save_iter //= 2
        
        print('Timestep doubled. Syncing particle velocity/position with DT =', DT)

    if adaptive_subcycling == 1:
        k_max           = np.pi / dx
        dispfreq        = (k_max ** 2) * (B_tot / (mu0 * dns)).max()             # Dispersion frequency
        dt_sc           = freq_res / dispfreq
        new_subcycles   = int(DT / dt_sc + 1)
        
        if subcycles < 0.75*new_subcycles:                                       
            subcycles *= 2
            print('Number of subcycles per timestep doubled to', subcycles)
            
        if subcycles > 3.0*new_subcycles and subcycles%2 == 0:                                      
            subcycles //= 2
            print('Number of subcycles per timestep halved to', subcycles)
            
        if subcycles >= 2000:
            subcycles = 2000
            sys.exit('Maximum number of subcycles reached :: Simulation aborted')

    return qq, DT, max_inc, part_save_iter, field_save_iter, change_flag, subcycles


#%% SAVE FUNCTIONS
def manage_directories():
    from shutil import rmtree
    print('Checking directories...')
    if (save_particles == 1 or save_fields == 1) == True:
        if os.path.exists('%s/%s' % (drive, save_path)) == False:
            os.makedirs('%s/%s' % (drive, save_path))                        # Create master test series directory
            print('Master directory created')

        path = ('%s/%s/run_%d' % (drive, save_path, run_num))          

        if os.path.exists(path) == False:
            os.makedirs(path)
            print('Run directory created')
        else:
            print('Run directory already exists')
            overwrite_flag = input('Overwrite? (Y/N) \n')
            if overwrite_flag.lower() == 'y':
                rmtree(path)
                os.makedirs(path)
            elif overwrite_flag.lower() == 'n':
                sys.exit('Program Terminated: Change run_num in simulation_parameters_1D')
            else:
                sys.exit('Unfamiliar input: Run terminated for safety')
    return


def store_run_parameters(dt, part_save_iter, field_save_iter, max_inc, max_time, subcycles):
    import pickle
    d_path = '%s/%s/run_%d/data/' % (drive, save_path, run_num)     # Set main dir for data
    f_path = d_path + '/fields/'
    p_path = d_path + '/particles/'

    for folder in [d_path, f_path, p_path]:
        if os.path.exists(folder) == False:                               # Create data directories
            os.makedirs(folder)

    # Save simulation parameters to file (Some unused, copied from PREDCORR)
    params = dict([('seed', seed),
                   ('Nj', Nj),
                   ('dt', dt),
                   ('max_inc', max_inc),
                   ('max_time', max_time),
                   ('NX', NX),
                   ('ND', ND),
                   ('NC', NC),
                   ('N' , N),
                   ('dxm', dxm),
                   ('dx', dx),
                   ('L', 0.0),
                   ('B_eq', B_eq),
                   ('xmax', xmax),
                   ('xmin', xmin),
                   ('B_xmax', B_xmax),
                   ('a', 0.0),
                   ('theta_xmax', 0.0),
                   ('theta_L', 0.0),
                   ('loss_cone', 0.0),
                   ('loss_cone_xmax', 0.0),
                   ('r_A', 0.0),
                   ('lat_A', 0.0),
                   ('B_A', 0.0),
                   ('rc_hwidth', 0.0),
                   ('ne', ne),
                   ('Te0', Te0),
                   ('ie', ie),
                   ('theta', 0.0),
                   ('part_save_iter', part_save_iter),
                   ('field_save_iter', field_save_iter),
                   ('max_wcinv', max_wcinv),
                   ('LH_frac', LH_frac),
                   ('freq_res', freq_res),
                   ('orbit_res', orbit_res),
                   ('run_desc', run_description),
                   ('method_type', 'CAM_CL_PARABOLIC_PARALLEL'),
                   ('particle_shape', 'TSC'),
                   ('field_periodic', field_periodic),
                   ('run_time', None),
                   ('loop_time', None),
                   ('homogeneous', homogenous),
                   ('particle_periodic', particle_periodic),
                   ('particle_reflect', particle_reflect),
                   ('particle_reinit', particle_reinit),
                   ('disable_waves', disable_waves),
                   ('source_smoothing', source_smoothing),
                   ('E_damping', 0),
                   ('quiet_start', quiet_start),
                   ('num_threads', nb.get_num_threads()),
                   ('subcycles', subcycles),
                   ('beta_flag', beta_flag)
                   ])

    with open(d_path + 'simulation_parameters.pckl', 'wb') as f:
        pickle.dump(params, f)
        f.close()
        
    print('Simulation parameters saved')
    
    # Save particle parameters to file (Need to change things into vth)
    p_file = os.path.join(d_path, 'particle_parameters')
    np.savez(p_file, idx_start   = idx_start,
                     idx_end     = idx_end,
                     species_lbl = species_lbl,
                     temp_color  = temp_color,
                     temp_type   = temp_type,
                     dist_type   = dist_type,
                     mass        = mass,
                     charge      = charge,
                     drift_v     = drift_v*va,
                     nsp_ppc     = nsp_ppc,
                     N_species   = N_species,
                     density     = density,
                     vth_par     = vth_par,
                     vth_perp    = vth_perp,
                     Tpar        = Tpar,
                     Tperp       = Tperp,
                     E_par       = E_par,
                     E_perp      = E_perp,
                     anisotropy  = anisotropy,
                     Bc          = Bc,
                     Te0         = None)
    
    print('Particle parameters saved')
    return


def save_field_data(dt, field_save_iter, qq, Ji, E, B, Ve, Te, dns, sim_time):
    #print('Saving field data')
    d_path = '%s/%s/run_%d/data/fields/' % (drive, save_path, run_num)
    r      = qq / field_save_iter

    d_fullpath = d_path + 'data%05d' % r
    
    np.savez(d_fullpath, E = E[:, 0:3], B = B[:, 0:3], Ji = Ji,
                         dns = dns, Ve = Ve[:, 0:3], Te = Te,
                         sim_time = sim_time,
                         damping_array  =np.zeros(B.shape[0]),
                         E_damping_array=np.zeros(E.shape[0]))
    return
    
    
def save_particle_data(dt, part_save_iter, qq, pos, vel, idx, sim_time):
    #print('Saving particle data')
    d_path = '%s/%s/run_%d/data/particles/' % (drive, save_path, run_num)
    r      = qq / part_save_iter

    d_filename = 'data%05d' % r
    d_fullpath = os.path.join(d_path, d_filename)
    np.savez(d_fullpath, pos=pos, vel=vel, idx=idx, sim_time = sim_time)
    return


def add_runtime_to_header(runtime):
    import pickle
    d_path = ('%s/%s/run_%d/data/' % (drive, save_path, run_num))     # Data path
    
    h_name = os.path.join(d_path, 'simulation_parameters.pckl')         # Header file path
    f      = open(h_name, 'rb')                                         # Open header file
    params = pickle.load(f)                                             # Load variables from header file into dict
    f.close()  
    
    params['run_time'] = runtime
    
    # Re-save
    with open(d_path + 'simulation_parameters.pckl', 'wb') as f:
        pickle.dump(params, f)
        f.close()
        print('Run time appended to simulation header file')
    return


import matplotlib.pyplot as plt
def diagnostic_field_plot(B, E, q_dens, Ji, Ve, Te,
                          B_damping_array, qq, DT, sim_time):
    '''
    Check field grid arrays, probably at every timestep
    '''
    print('Generating diagnostic plot for timestep', qq)
    # Check dir
    diagnostic_path = drive + save_path + 'run_{}/diagnostic_plots/'.format(run_num)
    if os.path.exists(diagnostic_path) == False:                                   # Create data directory
        os.makedirs(diagnostic_path)
    
    ## Initialize plots and prepare plotspace
    plt.ioff()
    fontsize = 14; fsize = 12; lpad = 20
    fig, axes = plt.subplots(5, ncols=3, figsize=(20,10), sharex=True)
    fig.patch.set_facecolor('w')   
    axes[0, 0].set_title('Diagnostics :: Grid Ouputs ::: {}[{}] :: {:.4f}s'.format(save_path.split('/')[2], run_num, round(sim_time, 4)),
                         fontsize=fontsize+4, family='monospace')

    background_B = eval_B0x(E_nodes)
    
    axes[0, 0].plot(B_nodes / dx, B_damping_array, color='k', label=r'$r_D(x)$') 
    axes[1, 0].plot(B_nodes / dx, B[:, 1]*1e9,     color='b', label=r'$B_y$') 
    axes[2, 0].plot(B_nodes / dx, B[:, 2]*1e9,     color='g', label=r'$B_z$')
    axes[3, 0].plot(E_nodes / dx, E[:, 1]*1e3, color='b', label=r'$E_y$')
    axes[4, 0].plot(E_nodes / dx, E[:, 2]*1e3, color='g', label=r'$E_z$')

    axes[0, 1].plot(E_nodes / dx, q_dens,   color='k', label=r'$n_e$')
    axes[1, 1].plot(E_nodes / dx, Ve[:, 1], color='b', label=r'$V_{ey}$')
    axes[2, 1].plot(E_nodes / dx, Ve[:, 2], color='g', label=r'$V_{ez}$')
    axes[3, 1].plot(E_nodes / dx, Ji[:, 1], color='b', label=r'$J_{iy}$' )
    axes[4, 1].plot(E_nodes / dx, Ji[:, 2], color='g', label=r'$J_{iz}$' )
    
    axes[0, 2].axhline(Te0, c='k', alpha=0.5, ls='--')
    axes[0, 2].plot(E_nodes / dx, Te, color='r',          label=r'$T_e$')
    axes[1, 2].plot(E_nodes / dx, Ve[:, 0], color='r',    label=r'$V_{ex}$')
    axes[2, 2].plot(E_nodes / dx, Ji[:, 0], color='r',    label=r'$J_{ix}$' )
    axes[3, 2].plot(E_nodes / dx, E[:, 0]*1e3, color='r', label=r'$E_x$')
    axes[4, 2].plot(B_nodes / dx, B[:, 0]*1e9, color='r',     label=r'$B_{wx}$')
    axes[4, 2].plot(E_nodes / dx, background_B, color='k', ls='--',    label=r'$B_{0x}$')
    

    axes[0, 0].set_ylabel('$r_D(x)$'     , rotation=0, labelpad=lpad, fontsize=fsize)
    axes[1, 0].set_ylabel('$B_y$\n(nT)'  , rotation=0, labelpad=lpad, fontsize=fsize)
    axes[2, 0].set_ylabel('$B_z$\n(nT)'  , rotation=0, labelpad=lpad, fontsize=fsize)
    axes[3, 0].set_ylabel('$E_y$\n(mV/m)', rotation=0, labelpad=lpad, fontsize=fsize)
    axes[4, 0].set_ylabel('$E_z$\n(mV/m)', rotation=0, labelpad=lpad, fontsize=fsize)
    
    axes[0, 1].set_ylabel('$n_e$\n$(cm^{-1})$', fontsize=fsize, rotation=0, labelpad=lpad)
    axes[1, 1].set_ylabel('$V_{ey}$'          , fontsize=fsize, rotation=0, labelpad=lpad)
    axes[2, 1].set_ylabel('$V_{ez}$'          , fontsize=fsize, rotation=0, labelpad=lpad)
    axes[3, 1].set_ylabel('$J_{iy}$'          , fontsize=fsize, rotation=0, labelpad=lpad)
    axes[4, 1].set_ylabel('$J_{iz}$'          , fontsize=fsize, rotation=0, labelpad=lpad)
    
    axes[0, 2].set_ylabel('$T_e$\n(eV)'     , fontsize=fsize, rotation=0, labelpad=lpad)
    axes[1, 2].set_ylabel('$V_{ex}$\n(m/s)' , fontsize=fsize, rotation=0, labelpad=lpad)
    axes[2, 2].set_ylabel('$J_{ix}$'        , fontsize=fsize, rotation=0, labelpad=lpad)
    axes[3, 2].set_ylabel('$E_x$\n(mV/m)'   , fontsize=fsize, rotation=0, labelpad=lpad)
    axes[4, 2].set_ylabel('$B_x$\n(nT)'     , fontsize=fsize, rotation=0, labelpad=lpad)
    
    fig.align_labels()
            
    for ii in range(3):
        axes[4, ii].set_xlabel('Position (m/dx)')
        for jj in range(5):
            axes[jj, ii].set_xlim(B_nodes[0] / dx, B_nodes[-1] / dx)
            axes[jj, ii].axvline(-NX//2, c='k', ls=':', alpha=0.5)
            axes[jj, ii].axvline( NX//2, c='k', ls=':', alpha=0.5)
            axes[jj, ii].ticklabel_format(axis='y', useOffset=False)
            axes[jj, ii].grid()
    
    plt.tight_layout(pad=1.0, w_pad=1.8)
    fig.subplots_adjust(hspace=0.125)
    plt.savefig(diagnostic_path + 'diag_field_{:07}'.format(qq), 
                facecolor=fig.get_facecolor(), edgecolor='none')
    plt.close('all')
    return

def dump_to_file(pos, vel, E_int, Ve, Te, B, Ji, q_dens, qq, folder='parallel', print_particles=False):
    import os
    np.set_printoptions(threshold=sys.maxsize)
    
    dirpath = drive + save_path + '/{}/timestep_{:05}/'.format(folder, qq) 
    if os.path.exists(dirpath) == False:
        os.makedirs(dirpath)
        
    print('Dumping arrays to file')
    if print_particles == True:
        with open(dirpath + 'pos.txt', 'w') as f:
            print(pos, file=f)
        with open(dirpath + 'vel.txt', 'w') as f:
            print(vel, file=f)
    with open(dirpath + 'E.txt', 'w') as f:
        print(E_int, file=f)
    with open(dirpath + 'Ve.txt', 'w') as f:
        print(Ve, file=f)
    with open(dirpath + 'Te.txt', 'w') as f:
        print(Te, file=f)
    with open(dirpath + 'B.txt', 'w') as f:
        print(B, file=f)
    with open(dirpath + 'Ji.txt', 'w') as f:
        print(Ji, file=f)
    with open(dirpath + 'rho.txt', 'w') as f:
        print(q_dens, file=f)

    np.set_printoptions(threshold=1000)
    return


#%% --- MAIN ---
# Misc softish-coded stuff    
min_dens            = 0.05                               # Allowable minimum charge density in a cell, as a fraction of ne*q
adaptive_timestep   = 1                                  # Flag (True/False) for adaptive timestep based on particle and field parameters
adaptive_subcycling = 1                                  # Flag (True/False) to adaptively change number of subcycles during run to account for high-frequency dispersion
default_subcycles   = 12                                 # Number of field subcycling steps for Cyclic Leapfrog


#################################
### FILENAMES AND DIRECTORIES ###
#################################

#### Read in command-line arguments, if present
import argparse as ap
parser = ap.ArgumentParser()
parser.add_argument('-r', '--runfile'   , default='_run_params.run', type=str)
parser.add_argument('-p', '--plasmafile', default='_plasma_params.plasma', type=str)
parser.add_argument('-n', '--run_num'   , default=-1, type=int)
args = vars(parser.parse_args())

# Check root directory (change if on RCG)
if os.name == 'posix':
    root_dir = os.path.dirname(sys.path[0])
else:
    root_dir = '..'
    
# Set input .run and .plasma files
run_input    = root_dir +  '/run_inputs/' + args['runfile']
plasma_input = root_dir +  '/run_inputs/' + args['plasmafile']



###########################
### LOAD RUN PARAMETERS ###
###########################
with open(run_input, 'r') as f:
    drive             = f.readline().split()[1]        # Drive letter or path for portable HDD e.g. 'E:/' or '/media/yoshi/UNI_HD/'
    save_path         = f.readline().split()[1]        # Series save dir   : Folder containing all runs of a series
    run_num           = f.readline().split()[1]        # Series run number : For multiple runs (e.g. parameter studies) with same overall structure (i.e. test series)

    save_particles    = int(f.readline().split()[1])   # Save data flag    : For later analysis
    save_fields       = int(f.readline().split()[1])   # Save plot flag    : To ensure hybrid is solving correctly during run
    seed              = f.readline().split()[1]        # RNG Seed          : Set to enable consistent results for parameter studies
    
    homogenous        = int(f.readline().split()[1])   # Set B0 to homogenous (as test to compare to parabolic)
    particle_periodic = int(f.readline().split()[1])   # Set particle boundary conditions to periodic
    particle_reflect  = int(f.readline().split()[1])   # Set particle boundary conditions to reflective
    particle_reinit   = int(f.readline().split()[1])   # Set particle boundary conditions to reinitialize
    field_periodic    = int(f.readline().split()[1])   # Set field boundary to periodic (False: Absorbtive Boundary Conditions)
    disable_waves     = int(f.readline().split()[1])   # Zeroes electric field solution at each timestep
    source_smoothing  = int(f.readline().split()[1])   # Smooth source terms with 3-point Gaussian filter
    E_damping         = int(f.readline().split()[1])   # Damp E in a manner similar to B for ABCs
    quiet_start       = int(f.readline().split()[1])   # Flag to use quiet start (False :: semi-quiet start)
    damping_multiplier= float(f.readline().split()[1]) # Multiplies the r-factor to increase/decrease damping rate.

    NX        = int(f.readline().split()[1])           # Number of cells - doesn't include ghost cells
    ND        = int(f.readline().split()[1])           # Damping region length: Multiple of NX (on each side of simulation domain)
    max_wcinv = float(f.readline().split()[1])         # Simulation runtime, in multiples of the ion gyroperiod (in seconds)
    dxm       = float(f.readline().split()[1])         # Number of c/wpi per dx (Ion inertial length: anything less than 1 isn't "resolvable" by hybrid code, anything too much more than 1 does funky things to the waveform)
    
    ie        = int(f.readline().split()[1])           # Adiabatic electrons. 0: off (constant), 1: on.
    rc_hwidth = f.readline().split()[1]                # Ring current half-width in number of cells (2*hwidth gives total cells with RC) 
      
    orbit_res = float(f.readline().split()[1])         # Orbit resolution
    freq_res  = float(f.readline().split()[1])         # Frequency resolution     : Fraction of angular frequency for multiple cyclical values
    part_res  = float(f.readline().split()[1])         # Data capture resolution in gyroperiod fraction: Particle information
    field_res = float(f.readline().split()[1])         # Data capture resolution in gyroperiod fraction: Field information

    run_description = f.readline()                     # Commentary to attach to runs, helpful to have a quick description

# Override because I keep forgetting to change this
if os.name == 'posix':
    drive = '/home/c3134027/'

# Set run number
if args['run_num'] != -1:                              # Check CLI, or
    run_num = args['run_num']
elif run_num != '-':                                       # Check input file, else
    run_num = int(run_num)
else:                                                  # Autoset
    if os.path.exists(drive + save_path) == False:
        run_num = 0
    else:
        run_num = len(os.listdir(drive + save_path))
    print('Run number AUTOSET to ', run_num)

if seed == '-':
    seed = None
else:
    seed = int(seed)

if __name__ == '__main__':
    manage_directories()

#######################################
### LOAD PARTICLE/PLASMA PARAMETERS ###
#######################################
with open(plasma_input, 'r') as f:
    species_lbl = np.array(f.readline().split()[1:])
    
    temp_color = np.array(f.readline().split()[1:])
    temp_type  = np.array(f.readline().split()[1:], dtype=int)
    dist_type  = np.array(f.readline().split()[1:], dtype=int)
    nsp_ppc    = np.array(f.readline().split()[1:], dtype=int)
    
    mass       = np.array(f.readline().split()[1:], dtype=float)
    charge     = np.array(f.readline().split()[1:], dtype=float)
    drift_v    = np.array(f.readline().split()[1:], dtype=float)
    density    = np.array(f.readline().split()[1:], dtype=float)*1e6
    anisotropy = np.array(f.readline().split()[1:], dtype=float)
                                       
    E_perp     = np.array(f.readline().split()[1:], dtype=float)
    E_e        = float(f.readline().split()[1])
    beta_flag  = int(f.readline().split()[1])

    L         = float(f.readline().split()[1])           # Field line L shell
    B_eq      = f.readline().split()[1]                  # Initial magnetic field at equator: None for L-determined value (in T) :: 'Exact' value in node ND + NX//2
    B_xmax_ovr= f.readline().split()[1]


if disable_waves == True:
    print('-- Wave solutions disabled, removing subcycles --')
    adaptive_timestep = adaptive_subcycling = 0
    default_subcycles = 1

B_eq      = float(B_eq)                                  # Unform initial magnetic field value (in T)
ne        = (density * charge).sum()                     # Electron density (in /m3, same as total ion density (for singly charged ions))

### -- Normalization of density override (e.g. Fu, Winkse)
if Fu_override == True:
    rat        = 5
    ne         = (rat*B_eq)**2 * e0 / me
    density    = np.array([0.05, 0.94, 0.01])*ne
### --- DELETE LATER

#%%### DERIVED SIMULATION PARAMETERS
E_par     = E_perp / (anisotropy + 1) 
charge    *= q                                           # Cast species charge to Coulomb
mass      *= mp                                          # Cast species mass to kg

particle_open = 0
if particle_reflect + particle_reinit + particle_periodic == 0:
    particle_open = 1

# Particle energy: If beta == 1, energies are in beta. If not, they are in eV 
if beta_flag == 1:
    Te0    = B_eq ** 2 * E_e    / (2 * mu0 * ne * kB)      # Temperatures of each species in Kelvin
    Tpar   = B_eq ** 2 * E_par  / (2 * mu0 * ne * kB)
    Tperp  = B_eq ** 2 * E_perp / (2 * mu0 * ne * kB)
    
    kbt_par    = E_par  * (B_eq ** 2) / (2 * mu0 * ne)
    kbt_per    = E_perp * (B_eq ** 2) / (2 * mu0 * ne)
    vth_perp   = np.sqrt(kbt_per /  mass)                # Perpendicular thermal velocities
    vth_par    = np.sqrt(kbt_par /  mass)                # Parallel thermal velocities
else:
    Te0        = E_e    * 11603.
    Tpar       = E_par  * 11603.
    Tperp      = E_perp * 11603.
    
    vth_perp   = np.sqrt(charge *  E_perp /  mass)       # Perpendicular thermal velocities
    vth_par    = np.sqrt(charge *  E_par  /  mass)       # Parallel thermal velocities

wpi        = np.sqrt(ne * q ** 2 / (mp * e0))            # Proton   Plasma Frequency, wpi (rad/s)
wpe        = np.sqrt(ne * q ** 2 / (me * e0))            # Proton   Plasma Frequency, wpi (rad/s)
va         = B_eq / np.sqrt(mu0*ne*mp)                   # Alfven speed: Assuming pure proton plasma

qm_ratios  = np.divide(charge, mass)
gyfreq     = q*B_eq/mp                                   # Proton   Gyrofrequency (rad/s) (since this will be the highest of all ion species)
e_gyfreq   = q*B_eq/me                                   # Electron Gyrofrequency (rad/s)

dx         = dxm * va / gyfreq                           # Alternate method of calculating dx (better for multicomponent plasmas)
dx2        = dxm * c / wpi                               # Spatial cadence, based on ion inertial length
xmin       = -NX * dx/2                                  # Minimum simulation dimension
xmax       =  NX * dx/2                                  # Maximum simulation dimension
NC         = NX + 2*ND                                   # Field array size (B: NC + 1, E: NC)
N          = nsp_ppc.sum()*NX                            # Number of Particles to simulate: # cells x # particles per cell, excluding ghost cells

Nj         = len(mass)                                   # Number of species
n_contr    = density / nsp_ppc                           # Species density contribution: Each macroparticle contributes this density to a cell

k_max      = np.pi / dx                                  # Maximum permissible wavenumber in system (SI???)
LH_frac    = 0.0                                         # Fraction of Lower Hybrid resonance: 
                                                         # Used to calculate electron resistivity by setting "anomalous"
                                                         # electron/ion collision as some multiple of the LHF. 0 disables e_resis.
LH_res_is  = 1. / (gyfreq * e_gyfreq) + 1. / wpi ** 2    # Lower Hybrid Resonance frequency, inverse squared
LH_res     = 1. / np.sqrt(LH_res_is)                     # Lower Hybrid Resonance frequency: DID I CHECK THIS???

e_resis     = (LH_frac * LH_res)  / (e0 * wpe ** 2)      # Electron resistivity (using intial conditions for wpi/wpe)
speed_ratio = c / va

# Number of sim particles for each species, total
N_species = nsp_ppc * NX
if field_periodic == 0:
    N_species += 2  

# Add number of spare particles proportional to percentage of total (50% standard, high but safe)
if particle_open == 1:
    spare_ppc  = N_species.sum() * 0.5
else:
    spare_ppc  = 0
N = N_species.sum() + int(spare_ppc)

if homogenous == 1:
    a      = 0
    B_xmax = B_eq
    
    # Also need to set any numeric values
    B_A            = 0.0
    loss_cone_eq   = 0.0
    loss_cone_xmax = 0.0
    theta_xmax     = 0.0
    lambda_L       = 0.0
    lat_A          = 0.0
    r_A            = 0.0
else:
    # GENERAL PARABOLIC FIELD
    if B_xmax_ovr == '-':
        a      = 4.5 / (L*RE)**2
        B_xmax = B_eq * (1 + a*xmax**2)
    else:
        a      = (B_xmax / B_eq - 1) / xmax**2
        B_xmax = B_xmax_ovr
    
    r_A        = 120e3
    lat_A      = np.arccos(np.sqrt((RE + r_A)/(RE*L)))       # Anchor latitude in radians
    B_A        = B_eq * np.sqrt(4 - 3*np.cos(lat_A) ** 2)\
                / (np.cos(lat_A) ** 6)                        # Magnetic field at anchor point
    
    lambda_L   = np.arccos(np.sqrt(1.0 / L)) 
    
    loss_cone_eq   = np.arcsin(np.sqrt(B_eq   / B_A))*180 / np.pi   # Equatorial loss cone in degrees
    loss_cone_xmax = np.arcsin(np.sqrt(B_xmax / B_A))               # Boundary loss cone in radians

    # NOT REALLY ANY WAY TO TELL MLAT WITH THIS METHOD
    theta_xmax = 0.0
    
if particle_open == 1:
    inject_rate = nsp_ppc * (vth_par / dx) / np.sqrt(2 * np.pi)
else:
    inject_rate = 0.0
 
idx_start  = np.asarray([np.sum(N_species[0:ii]    )     for ii in range(0, Nj)])    # Start index values for each species in order
idx_end    = np.asarray([np.sum(N_species[0:ii + 1])     for ii in range(0, Nj)])    # End   index values for each species in order   
 
B_nodes  = (np.arange(NC + 1) - NC // 2)       * dx      # B grid points position in space
E_nodes  = (np.arange(NC)     - NC // 2 + 0.5) * dx      # E grid points position in space
    
Bc       = np.zeros((NC + 1, 3), dtype=np.float64)       # Constant background field at B nodes
Bc[:, 0] = eval_B0x(B_nodes)                             # Set Bx initial
Bc[:, 1] = 0.                                            # Set By initial
Bc[:, 2] = 0.                                            # Set Bz initial

# E-field nodes around boundaries (used for sources and E-fields)
lo1 = ND - 1 ; lo2 = ND - 2             # Left outer (to boundary)
ro1 = ND + NX; ro2 = ND + NX + 1        # Right outer

li1 = ND         ; li2 = ND + 1         # Left inner
ri1 = ND + NX - 1; ri2 = ND + NX - 2    # Right inner
    
#%% DRIVEN WAVE STUFF (NOT YET IMPLEMENTED)
pol_wave    = 0         # 0: No wave, 1: Single point source, 2: Multi point source

# DRIVEN B PARAMS: Sine part
driven_freq = 2.2       # Driven wave frequency in Hz standard 2.2
driven_ampl = 50e-7     # Driven wave amplitude in A/m (I think?) Standard 50e-7

# Gaussian part
pulse_offset = 5.0      # Pulse center time (s)
pulse_width  = 1.0      # Pulse width (proportional to 2*std. 3*width decayed to 0.0123%) 

species_plasfreq_sq   = (density * charge ** 2) / (mass * e0)
species_gyrofrequency = qm_ratios * B_eq

# Looks right!
driven_rad = driven_freq * 2 * np.pi
driven_k   = (driven_rad / c) ** 2
driven_k  *= 1 - (species_plasfreq_sq / (driven_rad * (driven_rad - species_gyrofrequency))).sum()
driven_k   = np.sqrt(driven_k)


print('Run Started')
print('Run Series         : {}'.format(save_path.split('//')[-1]))
print('Run Number         : {}'.format(run_num))
print('Field save flag    : {}'.format(save_fields))
print('Particle save flag : {}\n'.format(save_particles))

print('Sim domain length  : {:5.2f}R_E'.format(2 * xmax / RE))
print('Density            : {:5.2f}cc'.format(ne / 1e6))
print('Equatorial B-field : {:5.2f}nT'.format(B_eq*1e9))
print('Boundary   B-field : {:5.2f}nT'.format(B_xmax*1e9))
print('Iono.      B-field : {:5.2f}mT'.format(B_A*1e6))
print('Equat. Loss cone   : {:<5.2f} degrees  '.format(loss_cone_eq))
print('Bound. Loss cone   : {:<5.2f} degrees  '.format(loss_cone_xmax * 180. / np.pi))
print('Maximum MLAT (+/-) : {:<5.2f} degrees  '.format(theta_xmax * 180. / np.pi))
print('Iono.   MLAT (+/-) : {:<5.2f} degrees\n'.format(lambda_L * 180. / np.pi))

print('Equat. Gyroperiod: : {}s'.format(round(2. * np.pi / gyfreq, 3)))
print('Inverse rad gyfreq : {}s'.format(round(1 / gyfreq, 3)))
print('Maximum sim time   : {}s ({} gyroperiods)\n'.format(round(max_wcinv /  gyfreq, 2), 
                                                           round(max_wcinv/(2*np.pi), 2)))
print('{} spatial cells, 2x{} damped cells'.format(NX, ND))
print('{} cells total'.format(NC))
print('{} particles total\n'.format(N))
    
    #%% BEGIN HYBRID
if __name__ == '__main__':
    start_time = timer()
    
    # Initialize arrays and initial conditions
    Ie       = np.zeros(N,       dtype=np.uint16)
    Ib       = np.zeros(N,       dtype=np.uint16)
    W_elec   = np.zeros((3, N),  dtype=np.float64)
    W_mag    = np.zeros((3, N),  dtype=np.float64)
    mp_flux  = np.zeros((2, Nj), dtype=np.float64)
    
    ni       = np.zeros((NC, Nj), dtype=np.float64)
    ni_init  = np.zeros((NC, Nj), dtype=np.float64)
    
    nu_init  = np.zeros((NC, Nj, 3), dtype=np.float64)
    nu_plus  = np.zeros((NC, Nj, 3), dtype=np.float64)
    nu_minus = np.zeros((NC, Nj, 3), dtype=np.float64)
    
    rho_half = np.zeros(NC, dtype=np.float64)
    rho_int  = np.zeros(NC, dtype=np.float64)
    
    J        = np.zeros((NC, 3), dtype=np.float64)
    J_plus   = np.zeros((NC, 3), dtype=np.float64)
    J_minus  = np.zeros((NC, 3), dtype=np.float64)
    L        = np.zeros( NC,     dtype=np.float64)
    G        = np.zeros((NC, 3), dtype=np.float64)
    
    B        = np.zeros((NC + 1, 3), dtype=np.float64)
    B2       = np.zeros((NC + 1, 3), dtype=np.float64)
    B_cent   = np.zeros((NC    , 3), dtype=np.float64)
    E        = np.zeros((NC    , 3), dtype=np.float64)
    Ve       = np.zeros((NC    , 3), dtype=np.float64)
    Te       = np.zeros((NC       ), dtype=np.float64)

    temp3d   = np.zeros((NC + 1, 3), dtype=np.float64)

    if quiet_start == 0:
        pos, idx = uniform_distribution()
        vel      = gaussian_distribution()
    else:
        pos, vel, idx = init_quiet_start()

    assign_weighting_TSC(pos, Ie, W_elec)

    _DT, max_inc, part_save_iter, field_save_iter, subcycles, B_damping_array = set_timestep(vel)

    print('Loading initial state...\n')
    init_collect_moments(pos, vel, Ie, W_elec, idx, ni_init, nu_init, ni, nu_plus, 
                         rho_int, rho_half, J, J_plus, L, G, 0.5*_DT)
    get_B_cent(B, B_cent)
    
    # Put init into qq = 0 and save as usual, qq = 1 will be at t = dt
    # Need to change this so the initial state gets saved?
    qq      = 0; sim_time = 0.0
    print('Starting loop...')
    while qq < max_inc:
        #dump_to_file(pos, vel, E, Ve, Te, B, J, rho_int, qq, folder='CAM_CL_srctest_srcparalleloff', print_particles=False)
        #diagnostic_field_plot(B, E, rho_int, J, Ve, Te, B_damping_array, qq, DT, sim_time)
        
        ############################
        ##### EXAMINE TIMESTEP #####
        ############################
        if adaptive_timestep == 1:
            qq, _DT, max_inc, part_save_iter, field_save_iter, change_flag, subcycles =\
                check_timestep(qq, _DT, pos, vel, Ie, W_elec, B, B_cent, E, rho_int, 
                               max_inc, part_save_iter, field_save_iter, subcycles)
    
            # Collect new moments and desync position and velocity
            if change_flag == 1:
                # If timestep was doubled, do I need to consider 0.5dt's worth of
                # new particles? Maybe just disable the doubling until I work this out
                init_collect_moments(pos, vel, Ie, W_elec, idx, ni_init, nu_init, ni, nu_plus, 
                         rho_int, rho_half, J, J_plus, L, G, 0.5*_DT)

        
        #######################
        ###### MAIN LOOP ######
        #######################
        cyclic_leapfrog(B, B2, B_cent, rho_int, J, temp3d, _DT, subcycles, B_damping_array)
        E, Ve, Te = calculate_E(B, B_cent, J, rho_half)

        push_current(J_plus, J, E, B, B_cent, L, G, _DT)
        E, Ve, Te = calculate_E(B, B_cent, J, rho_half)
        
        assign_weighting_TSC(pos, Ib, W_mag, E_nodes=False)
        velocity_update(pos, vel, Ie, W_elec, Ib, W_mag, idx, B, E, _DT)

        # Store pc(1/2) here while pc(3/2) is collected
        rho_int[:]  = rho_half[:] 
        collect_moments(pos, vel, Ie, W_elec, idx, ni, nu_plus, nu_minus, 
                              rho_half, J_minus, J_plus, L, G, _DT)
        
        rho_int += rho_half
        rho_int /= 2.0
        J        = 0.5 * (J_plus  +  J_minus)

        cyclic_leapfrog(B, B2, B_cent, rho_int, J, temp3d, _DT, subcycles, B_damping_array)
        E, Ve, Te   = calculate_E(B, B_cent, J, rho_int)

        ########################
        ##### OUTPUT DATA  #####
        ########################
        if qq%part_save_iter == 0 and save_particles == 1:
            save_particle_data(_DT, part_save_iter, qq, pos, vel, idx, sim_time)

        if qq%field_save_iter == 0 and save_fields == 1:
            save_field_data(_DT, field_save_iter, qq, J, E, B, Ve, Te, rho_int, sim_time)
        
        if qq%100 == 0:
            running_time = int(timer() - start_time)
            hrs          = running_time // 3600
            rem          = running_time %  3600
            
            mins         = rem // 60
            sec          = rem %  60
            
            print('Step {} of {} :: Current runtime {:02}:{:02}:{:02}'.format(qq, max_inc, hrs, mins, sec))

        qq        += 1
        sim_time  += _DT
        
    runtime = round(timer() - start_time,2) 
    print('Run complete : {} s'.format(runtime))
    if save_fields == 1 or save_particles == 1:
        add_runtime_to_header(runtime)
        fin_path = '%s/%s/run_%d/run_finished.txt' % (drive, save_path, run_num)
        with open(fin_path, 'w') as open_file:
            pass