## PYTHON MODULES ##
from timeit import default_timer as timer
import numpy as np
import numba as nb
import sys, os, pdb

do_parallel=True
#nb.set_num_threads(8)         # Uncomment to manually set number of threads, otherwise will use all available

### PHYSICAL CONSTANTS ###
q   = 1.602177e-19                          # Elementary charge (C)
c   = 2.998925e+08                          # Speed of light (m/s)
mp  = 1.672622e-27                          # Mass of proton (kg)
me  = 9.109384e-31                          # Mass of electron (kg)
kB  = 1.380649e-23                          # Boltzmann's Constant (J/K)
e0  = 8.854188e-12                          # Epsilon naught - permittivity of free space
mu0 = (4e-7) * np.pi                        # Magnetic Permeability of Free Space (SI units)
RE  = 6.371e6                               # Earth radius in metres

#%% --- FUNCTIONS ---
#%% INITIALIZATION
def uniform_distribution():
    '''Creates an analytically uniform distribution of N numbers within each cell boundary

    INPUT:
        ppc       -- Number of particles per cell, per species

    OUTPUT:
        dist -- numpy ndarray containing numerical distribution
    '''
    dist = np.zeros(N)
    idx  = np.zeros(N, dtype=np.uint8)

    for jj in range(Nj):                    # For each species
        acc = 0
        idx[idx_start[jj]: idx_end[jj]] = jj
        
        for ii in range(NX):                # For each cell
            n_particles = nsp_ppc[jj]

            for kk in range(n_particles):   # For each particle in that cell
                dist[idx_start[jj] + acc + kk] = dx*(float(kk) / n_particles + ii)
            acc += n_particles

    return dist, idx


def gaussian_distribution():
    '''Creates an N-sampled normal distribution across all particle species within each simulation cell

    INPUT:
        N   -- Number of particles to distribute
        idx -- Index identifier for particle type : Correlates to parameters in part_params.py

    OUTPUT:
        dist -- Output distribution: Maxwellian, as generated by numpy's random.normal in 3 dimensions
    '''
    np.random.seed(seed)         # Random seed
    dist = np.zeros((3, N))      # Initialize array

    for jj in range(Nj):
        acc = 0                  # Species accumulator
        for ii in range(NX):
            n_particles = nsp_ppc[jj]
            dist[0, (idx_start[jj] + acc): ( idx_start[jj] + acc + n_particles)] = np.random.normal(0, np.sqrt((kB *  Tpar[ jj]) /  mass[jj]), n_particles) +  drift_v[jj]
            dist[1, (idx_start[jj] + acc): ( idx_start[jj] + acc + n_particles)] = np.random.normal(0, np.sqrt((kB *  Tperp[jj]) /  mass[jj]), n_particles)
            dist[2, (idx_start[jj] + acc): ( idx_start[jj] + acc + n_particles)] = np.random.normal(0, np.sqrt((kB *  Tperp[jj]) /  mass[jj]), n_particles)
            acc += n_particles
    
    # Rotate if theta != 0
    dist[0] = dist[0] * np.cos(np.pi * theta / 180.) - dist[2] * np.sin(np.pi * theta / 180.)
    dist[2] = dist[2] * np.cos(np.pi * theta / 180.) + dist[0] * np.sin(np.pi * theta / 180.)
    return dist


def init_quiet_start():
    '''Creates an N-sampled normal distribution across all particle species within each simulation cell

    OUTPUT:
        pos -- 1xN array of particle positions. Pos[0] is uniformly distributed with boundaries depending on its temperature type
        vel -- 3xN array of particle velocities. Each component initialized as a Gaussian with a scale factor determined by the species perp/para temperature
        idx -- N   array of particle indexes, indicating which species it belongs to. Coded as an 8-bit signed integer, allowing values between +/-128
    
    New code: Removed all 3D position things because we won't need it for long. Check this later, since its easy to change
            Also removed all references to dist_type since initializing particles in the middle is stupid.
    '''
    pos = np.zeros(N, dtype=np.float64)
    vel = np.zeros((3, N), dtype=np.float64)
    idx = np.ones(N,       dtype=np.int8) * -1
    np.random.seed(seed)

    for jj in range(Nj):
        idx[idx_start[jj]: idx_end[jj]] = jj          # Set particle idx
        
        sf_par = np.sqrt(kB *  Tpar[ jj] /  mass[jj])  # Scale factors for velocity initialization
        sf_per = np.sqrt(kB *  Tperp[jj] /  mass[jj])
        
        half_n = nsp_ppc[jj] // 2                     # Half particles per cell - doubled later

        # Load particles in each applicable cell
        acc = 0; offset  = 0
        for ii in range(NX):                
            # Particle index ranges
            st = idx_start[jj] + acc
            en = idx_start[jj] + acc + half_n
            
            # Set position for half: Analytically uniform
            for kk in range(half_n):
                pos[st + kk] = dx*(float(kk) / (half_n - offset) + ii)
           
            # Set velocity for half: Randomly Maxwellian
            vel[0, st: en] = np.random.normal(0, sf_par, half_n) +  drift_v[jj]
            vel[1, st: en] = np.random.normal(0, sf_per, half_n)
            vel[2, st: en] = np.random.normal(0, sf_per, half_n)
                                
            pos[en: en + half_n] = pos[st: en]                      # Other half, same position
            vel[0, en: en + half_n] = vel[0, st: en] *  1.0     # Set parallel
            vel[1, en: en + half_n] = vel[1, st: en] * -1.0         # Invert perp velocities (v2 = -v1)
            vel[2, en: en + half_n] = vel[2, st: en] * -1.0
            
            acc                    += half_n * 2
            
    # Rotate if theta != 0
    if theta != 0:
        vel[0] = vel[0] * np.cos(np.pi * theta / 180.) - vel[2] * np.sin(np.pi * theta / 180.)
        vel[2] = vel[2] * np.cos(np.pi * theta / 180.) + vel[0] * np.sin(np.pi * theta / 180.)
    return pos, vel, idx


def set_timestep(vel):
    # NOTE: Can probably ease off on the ion_ts once I validate this 
    ion_ts   = dxm * orbit_res / gyfreq           # Timestep to resolve gyromotion
    vel_ts   = 0.5*dx / np.max(np.abs(vel[0, :])) # Timestep to satisfy CFL condition: Fastest particle doesn't traverse more than half a cell in one time step

    DT       = min(ion_ts, vel_ts)
    max_time = max_wcinv / gyfreq                 # Total runtime in seconds
    max_inc  = int(max_time / DT) + 1             # Total number of time steps

    if part_res == 0:
        part_save_iter = 1
    else:
        part_save_iter = int(part_res / (DT*gyfreq))

    if field_res == 0:
        field_save_iter = 1
    else:
        field_save_iter = int(field_res / (DT*gyfreq))

    print('Timestep: %.4fs, %d iterations total' % (DT, max_inc))
    
    if adaptive_subcycling == True:
        k_max      = np.pi / dx
        dispfreq   = (k_max ** 2) * B0 / (mu0 * ne * q)            # Dispersion frequency (units of k?)
        dt_sc      = freq_res / dispfreq
        subcycles  = int(DT / dt_sc + 1)
        print('Number of subcycles required: {}'.format(subcycles))
    else:
        subcycles = subcycles
        print('Number of subcycles set at default: {}'.format(subcycles))
    
    if save_fields == 1 or save_particles == 1:
        store_run_parameters(DT, part_save_iter, field_save_iter, max_inc, max_time)
        
    return DT, max_inc, part_save_iter, field_save_iter, subcycles


#%% PARTICLES 
@nb.njit(parallel=do_parallel)
def assign_weighting_TSC(pos, I, W, E_nodes=True):
    '''Triangular-Shaped Cloud (TSC) weighting scheme used to distribute particle
    densities to nodes and interpolate field values to particle positions.
        
    NOTE: The addition of `epsilon' in left_node prevents banker's rounding in
    left_node due to precision limits.
    '''
    Np      = pos.shape[0]
    epsilon = 1e-15
    
    if E_nodes == True:
        grid_offset   = 0.5
    else:
        grid_offset   = 1.0
    
    for ii in nb.prange(Np):
        I[ii]       = int(round(pos[ii] / dx + grid_offset + epsilon) - 1.0)
        delta_left  = I[ii] - (pos[ii] + epsilon) / dx - grid_offset
    
        W[0, ii] = 0.5  * np.square(1.5 - abs(delta_left))
        W[1, ii] = 0.75 - np.square(delta_left + 1.)
        W[2, ii] = 1.0  - W[0, ii] - W[1, ii]
    return


@nb.njit(parallel=do_parallel)
def velocity_update(pos, vel, Ie, W_elec, Ib, W_mag, idx, B, E, dt):
    assign_weighting_TSC(pos, Ib, W_mag, E_nodes=False)
    
    for ii in nb.prange(pos.shape[0]):
        # Calculate wave fields at particle position
        _Ep = np.zeros(3, dtype=np.float64)  
        _Bp = np.zeros(3, dtype=np.float64)
        
        for jj in nb.prange(3):
            for kk in nb.prange(3):
                _Ep[kk] += E[Ie[ii] + jj, kk] * W_elec[jj, ii]   
                _Bp[kk] += B[Ib[ii] + jj, kk] * W_mag[ jj, ii]   
# =============================================================================
#         Jp = J[Ie    , 0:3] * W_elec[0]                 \
#            + J[Ie + 1, 0:3] * W_elec[1]                 \
#            + J[Ie + 2, 0:3] * W_elec[2]                 # Current at particle location
#            
#         Ep -= (charge[idx] / q) * e_resis * Jp          # "Effective" E-field accounting for electron resistance
# =============================================================================                

        # Start Boris Method
        qmi = 0.5 * DT * qm_ratios[idx[ii]]                             # q/m variable including dt
        T   = qmi * _Bp 
        S   = 2.*T / (1. + T[0]*T[0] + T[1]*T[1] + T[2]*T[2])

        # vel -> v_minus
        vel[0, ii] += qmi * _Ep[0]
        vel[1, ii] += qmi * _Ep[1]
        vel[2, ii] += qmi * _Ep[2]
            
        # Calculate v_prime (maybe use a temp array here?)
        v_prime    = np.zeros(3, dtype=np.float64)
        v_prime[0] = vel[0, ii] + vel[1, ii] * T[2] - vel[2, ii] * T[1]
        v_prime[1] = vel[1, ii] + vel[2, ii] * T[0] - vel[0, ii] * T[2]
        v_prime[2] = vel[2, ii] + vel[0, ii] * T[1] - vel[1, ii] * T[0]
        
        # vel_minus -> vel_plus
        vel[0, ii] += v_prime[1] * S[2] - v_prime[2] * S[1]
        vel[1, ii] += v_prime[2] * S[0] - v_prime[0] * S[2]
        vel[2, ii] += v_prime[0] * S[1] - v_prime[1] * S[0]
        
        # vel_plus -> vel (updated)
        vel[0, ii] += qmi * _Ep[0]
        vel[1, ii] += qmi * _Ep[1]
        vel[2, ii] += qmi * _Ep[2]
    return


@nb.njit(parallel=do_parallel)
def position_update(pos, vel, Ie, W_elec, dt):
    '''Updates the position of the particles using x = x0 + vt. 
    Also updates particle nearest node and weighting.
    '''
    for ii in nb.prange(pos.shape[0]):
        pos[ii] += vel[0, ii] * dt
        
        if pos[ii] < xmin:
            pos[ii] += xmax
        elif pos[ii] > xmax:
            pos[ii] -= xmax
            
    assign_weighting_TSC(pos, Ie, W_elec)
    return




#%% SOURCES
@nb.njit()
def push_current(J_in, J_out, E, B, L, G, dt):
    '''Uses an MHD-like equation to advance the current with a moment method as 
    per Matthews (1994) CAM-CL method. Fills in ghost cells at edges (excluding very last one)
    
    INPUT:
        J  -- Ionic current (J plus)
        E  -- Electric field
        B  -- Magnetic field (offset from E by 0.5dx)
        L  -- "Lambda" MHD variable
        G  -- "Gamma"  MHD variable
        dt -- Timestep
        
    OUTPUT:
        J_plus in main() becomes J_half (same memory space)
    '''
    J_out *= 0
    B_center     = interpolate_to_center_cspline3D(B)
    G_cross_B    = cross_product(G, B_center)
    
    for ii in range(3):
        J_out[:, ii] = J_in[:, ii] + 0.5*dt * (L * E[:, ii] + G_cross_B[:, ii]) 

    J_out[0]                    = J_out[J_out.shape[0] - 3]
    J_out[J_out.shape[0] - 2]   = J_out[1]
    J_out[J_out.shape[0] - 1]   = J_out[2]
    return


@nb.njit(parallel=do_parallel)
def deposit_both_moments(pos, vel, Ie, W_elec, idx, n_i, nu_i):
    '''Collect number and velocity moments in each cell, weighted by their distance
    from cell nodes.

    INPUT:
        pos    -- Particle positions (x)
        vel    -- Particle 3-velocities
        Ie     -- Particle leftmost to nearest E-node
        W_elec -- Particle TSC weighting across nearest, left, and right nodes
        idx    -- Particle species identifier

    OUTPUT:
        n_i    -- Species number moment array(size, Nj)
        nu_i   -- Species velocity moment array (size, Nj)
    '''    
    for ii in nb.prange(pos.shape[0]):
        I   = Ie[ ii]
        sp  = idx[ii]
    
        for kk in range(3):
            nu_i[I,     sp, kk] += W_elec[0, ii] * vel[kk, ii]
            nu_i[I + 1, sp, kk] += W_elec[1, ii] * vel[kk, ii]
            nu_i[I + 2, sp, kk] += W_elec[2, ii] * vel[kk, ii]
        
        n_i[I,     sp] += W_elec[0, ii]
        n_i[I + 1, sp] += W_elec[1, ii]
        n_i[I + 2, sp] += W_elec[2, ii]

    manage_ghost_cells(n_i)
    manage_ghost_cells(nu_i)
    return


@nb.njit(parallel=do_parallel)
def deposit_velocity_moments(vel, Ie, W_elec, idx, nu_i):
    '''Collect velocity moment in each cell, weighted by their distance
    from cell nodes.

    INPUT:
        vel    -- Particle 3-velocities
        Ie     -- Particle leftmost to nearest E-node
        W_elec -- Particle TSC weighting across nearest, left, and right nodes
        idx    -- Particle species identifier
        
    OUTPUT:
        nu_i   -- Species velocity moment array (size, Nj)
    '''
    for ii in nb.prange(vel.shape[1]):
        I   = Ie[ ii]
        sp  = idx[ii]
        
        for kk in range(3):
            nu_i[I,     sp, kk] += W_elec[0, ii] * vel[kk, ii]
            nu_i[I + 1, sp, kk] += W_elec[1, ii] * vel[kk, ii]
            nu_i[I + 2, sp, kk] += W_elec[2, ii] * vel[kk, ii]
                      
    nu_i  = manage_ghost_cells(nu_i)
    return


@nb.njit()
def init_collect_moments(pos, vel, Ie, W_elec, idx, ni_init, nu_init, ni, nu_plus, 
                         rho_0, rho, J_init, J_plus, L, G, dt):
    '''Moment collection and position advance function. Specifically used at initialization or
    after timestep synchronization.

    INPUT:
        pos    -- Particle positions (x)
        vel    -- Particle 3-velocities
        Ie     -- Particle leftmost to nearest E-node
        W_elec -- Particle TSC weighting across nearest, left, and right nodes
        idx    -- Particle species identifier
        DT     -- Timestep for position advance
        
    OUTPUT:
        pos     -- Advanced particle positions
        Ie      -- Updated leftmost to nearest E-nodes
        W_elec  -- Updated TSC weighting coefficients
        rho_0   -- Charge  density at initial time (p0)
        rho     -- Charge  density at +0.5 timestep
        J_init  -- Current density at initial time (J0)
        J_plus  -- Current density at +0.5 timestep
        G       -- "Gamma"  MHD variable for current advance : Current-like
        L       -- "Lambda" MHD variable for current advance :  Charge-like
    '''
    ni      *= 0.0
    ni_init *= 0.0
    rho_0   *= 0.0
    rho     *= 0.0
    nu_init *= 0.0
    nu_plus *= 0.0
    J_init  *= 0.0
    J_plus  *= 0.0
    L       *= 0.0
    G       *= 0.0
                         
    deposit_both_moments(pos, vel, Ie, W_elec, idx, ni_init, nu_init)      # Collects sim_particles/cell/species
    position_update(pos, vel, Ie, W_elec, dt)
    deposit_both_moments(pos, vel, Ie, W_elec, idx, ni, nu_plus)

    if source_smoothing == 1:
        for jj in range(Nj):
            ni[:, jj]  = smooth(ni[:, jj])
        
            for kk in range(3):
                nu_plus[:, jj, kk] = smooth(nu_plus[:,  jj, kk])
                nu_init[:, jj, kk] = smooth(nu_init[:, jj, kk])
    
    for jj in range(Nj):
        rho_0   += ni_init[:, jj]   * n_contr[jj] * charge[jj]
        rho     += ni[:, jj]        * n_contr[jj] * charge[jj]
        L       += ni[:, jj]        * n_contr[jj] * charge[jj] ** 2 / mass[jj]
        
        for kk in range(3):
            J_init[:, kk]  += nu_init[:, jj, kk] * n_contr[jj] * charge[jj]
            J_plus[ :, kk] += nu_plus[:, jj, kk] * n_contr[jj] * charge[jj]
            G[      :, kk] += nu_plus[:, jj, kk] * n_contr[jj] * charge[jj] ** 2 / mass[jj]
    
    for ii in range(rho_0.shape[0]):
        if rho_0[ii] < min_dens * ne * q:
            rho_0[ii] = min_dens * ne * q
            
        if rho[ii] < min_dens * ne * q:
            rho[ii] = min_dens * ne * q
    return


@nb.njit()
def collect_moments(pos, vel, Ie, W_elec, idx, ni, nu_plus, nu_minus, 
                         rho, J_minus, J_plus, L, G, dt):
    '''
    Moment collection and position advance function.

    INPUT:
        pos    -- Particle positions (x)
        vel    -- Particle 3-velocities
        Ie     -- Particle leftmost to nearest E-node
        W_elec -- Particle TSC weighting across nearest, left, and right nodes
        idx    -- Particle species identifier
        DT     -- Timestep for position advance
        
    OUTPUT:
        pos     -- Advanced particle positions
        Ie      -- Updated leftmost to nearest E-nodes
        W_elec  -- Updated TSC weighting coefficients
        rho     -- Charge  density at +0.5 timestep
        J_plus  -- Current density at +0.5 timestep
        J_minus -- Current density at initial time (J0)
        G       -- "Gamma"  MHD variable for current advance
        L       -- "Lambda" MHD variable for current advance    
    '''
    ni       *= 0.0
    rho      *= 0.0
    nu_minus *= 0.0
    nu_plus  *= 0.0
    J_minus  *= 0.0
    J_plus   *= 0.0
    L        *= 0.0
    G        *= 0.0
    
    deposit_velocity_moments(vel, Ie, W_elec, idx, nu_minus)
    position_update(pos, vel, Ie, W_elec, dt)
    deposit_both_moments(pos, vel, Ie, W_elec, idx, ni, nu_plus)
    
    if source_smoothing == 1:
        for jj in range(Nj):
            ni[:, jj]  = smooth(ni[:, jj])
        
            for kk in range(3):
                nu_plus[ :, jj, kk] = smooth(nu_plus[:,  jj, kk])
                nu_minus[:, jj, kk] = smooth(nu_minus[:, jj, kk])
    
    for jj in range(Nj):
        rho  += ni[:, jj] * n_contr[jj] * charge[jj]
        L    += ni[:, jj] * n_contr[jj] * charge[jj] ** 2 / mass[jj]
        
        for kk in range(3):
            J_minus[:, kk] += nu_minus[:, jj, kk] * n_contr[jj] * charge[jj]
            J_plus[ :, kk] += nu_plus[ :, jj, kk] * n_contr[jj] * charge[jj]
            G[      :, kk] += nu_plus[ :, jj, kk] * n_contr[jj] * charge[jj] ** 2 / mass[jj]
        
    for ii in range(rho.shape[0]):
        if rho[ii] < min_dens * ne * q:
            rho[ii] = min_dens * ne * q
            
    return


@nb.njit()
def smooth(function):
    '''
    Smoothing function: Applies Gaussian smoothing routine across adjacent cells. 
    Assummes no contribution from ghost cells.
    '''
    size         = function.shape[0]
    new_function = np.zeros(size)

    for ii in np.arange(1, size - 1):
        new_function[ii - 1] = 0.25*function[ii] + new_function[ii - 1]
        new_function[ii]     = 0.50*function[ii] + new_function[ii]
        new_function[ii + 1] = 0.25*function[ii] + new_function[ii + 1]

    # Move Ghost Cell Contributions: Periodic Boundary Condition
    new_function[1]        += new_function[size - 1]
    new_function[size - 2] += new_function[0]

    # Set ghost cell values to mirror corresponding real cell
    new_function[0]        = new_function[size - 2]
    new_function[size - 1] = new_function[1]
    return new_function


@nb.njit()
def manage_ghost_cells(arr):
    '''
    Deals with ghost cells: Moves their contributions and mirrors their counterparts.
    Works like a charm if spatial dimensions always come first in an array.
   '''
    arr[NX]     += arr[0]                 # Move contribution: Start to end
    arr[1]      += arr[NX + 1]            # Move contribution: End to start

    arr[NX + 1]  = arr[1]                 # Fill ghost cell: End
    arr[0]       = arr[NX]                # Fill ghost cell: Start
    
    arr[NX + 2]  = arr[2]                 # This one doesn't get used, but prevents nasty nan's from being in array.
    return


#%% FIELDS

@nb.njit()
def get_curl_B(field):
    ''' Returns a vector quantity for the curl of a field valid at the positions 
    between its gridpoints (i.e. curl(B) -> E-grid, etc.)
    
    INPUT:
        field    -- The 3D field to take the curl of
        DX       -- Spacing between the nodes, mostly for diagnostics. 
                    Defaults to grid spacing specified at initialization.
                 
    OUTPUT:
        curl  -- Finite-differenced solution for the curl of the input field.
        
    NOTE: This function will only work with this specific 1D hybrid code due to both 
          E and B fields having the same number of nodes (due to TSC weighting) and
         the lack of derivatives in y, z
    '''
    curl = np.zeros(field.shape)
    
    for ii in np.arange(1, field.shape[0]):
        curl[ii - 1, 1] = - (field[ii, 2] - field[ii - 1, 2])
        curl[ii - 1, 2] =    field[ii, 1] - field[ii - 1, 1]
    
    # Assign ghost cell values
    curl[field.shape[0] - 1] = curl[2]
    curl[field.shape[0] - 2] = curl[1]
    curl[0] = curl[field.shape[0] - 3]
    curl   /= dx
    return curl


@nb.njit()
def get_curl_E(field, curl):
    ''' Returns a vector quantity for the curl of a field valid at the positions 
    between its gridpoints (i.e. curl(E) -> B-grid, etc.)
    
    INPUT:
        field    -- The 3D field to take the curl of
        DX       -- Spacing between the nodes, mostly for diagnostics. 
                    Defaults to grid spacing specified at initialization.
                 
    OUTPUT:
        curl  -- Finite-differenced solution for the curl of the input field.
        
    NOTE: This function will only work with this specific 1D hybrid code due to both 
          E and B fields having the same number of nodes (due to TSC weighting) and
         the lack of derivatives in y, z
    '''   
    curl *= 0.
    for ii in np.arange(1, field.shape[0]):
        curl[ii, 1] = - (field[ii, 2] - field[ii - 1, 2])
        curl[ii, 2] =    field[ii, 1] - field[ii - 1, 1]

    set_periodic_boundaries(curl)
    curl /= dx
    return


@nb.njit()
def get_electron_temp(qn):
    '''
    Calculate the electron temperature in each cell. Depends on the charge density of each cell
    and the treatment of electrons: i.e. isothermal (ie=0) or adiabatic (ie=1)
    '''
    if ie == 0:
        te      = np.ones(qn.shape[0]) * Te0
    elif ie == 1:
        gamma_e = 5./3. - 1.
        te      = Te0 * np.power(qn / (q*ne), gamma_e)
    return te


@nb.njit()
def get_grad_P(qn, te, inter_type=1):
    '''
    Returns the electron pressure gradient (in 1D) on the E-field grid using P = nkT and 
    finite difference.
    
    INPUT:
        qn -- Grid charge density
        te -- Grid electron temperature
        DX -- Grid separation, used for diagnostic purposes. Defaults to simulation dx.
        inter_type -- Linear (0) or cubic spline (1) interpolation.
        
    NOTE: Interpolation is needed because the finite differencing causes the result to be deposited on the 
    B-grid. Moving it back to the E-grid requires an interpolation. Cubic spline is desired due to its smooth
    derivatives and its higher order weighting (without the polynomial craziness)
    '''
    grad_pe_B     = np.zeros(qn.shape[0])
    grad_P        = np.zeros(qn.shape[0])
    Pe            = qn * kB * te / q

    for ii in np.arange(1, qn.shape[0]):
        grad_pe_B[ii] = (Pe[ii] - Pe[ii - 1])
        
    grad_pe_B[0] = grad_pe_B[qn.shape[0] - 3]
    
    # Re-interpolate to E-grid
    if inter_type == 0:
        grad_P = interpolate_to_center_linear_1D(grad_pe_B)           
    elif inter_type == 1:
        grad_P = interpolate_to_center_cspline1D(grad_pe_B)

    grad_P[0]               = grad_P[qn.shape[0] - 3]
    grad_P[qn.shape[0] - 2] = grad_P[1]
    grad_P[qn.shape[0] - 1] = grad_P[2] 
    grad_P /= dx
    return grad_P


@nb.njit()
def set_periodic_boundaries(B):
    ''' 
    Set boundary conditions for the magnetic field (or values on the B-grid, i.e. curl[E]): 
     -- Average "end" values and assign to first and last grid point
     -- Set ghost cell values so TSC weighting works
    '''
    end_bit = 0.5*(B[1] + B[NX+1])                              # Average end values (for periodic boundary condition)
    B[1]      = end_bit
    B[NX+1]   = end_bit
    
    B[0]      = B[NX]
    B[NX+2]   = B[2]
    return


@nb.njit()
def cyclic_leapfrog(B1, B2, rho, J, curl, DT, subcycles):
    '''
    Solves for the magnetic field push by keeping two copies and subcycling between them,
    averaging them at the end of the cycle as per Matthews (1994). The source terms are
    unchanged during the subcycle step. This method damps the high frequency dispersion 
    inherent in explicit hybrid simulations.
    
    INPUT:
        B1    -- Magnetic field to update (return value comes through here)
        B2    -- Empty array for second copy
        rho_i -- Total ion charge density
        J_i   -- Total ionic current density
        DT    -- Master simulation timestep. This function advances the field by 0.5*DT
        subcycles -- The number of subcycle steps to be performed. 
    '''
    H     = 0.5 * DT
    dh    = H / subcycles
    B2[:] = B1[:]

    ## DESYNC SECOND FIELD COPY - PUSH BY DH ##
    E, Ve, Te = calculate_E(B1, J, rho)
    get_curl_E(E, curl) 
    B2       -= dh * curl
    set_periodic_boundaries(B2)                              

    ## RETURN IF NO SUBCYCLES REQUIRED ##
    if subcycles == 1:
        return B2

    ## MAIN SUBCYCLE LOOP ##
    for ii in range(subcycles - 1):             
        if ii%2 == 0:
            E, Ve, Te = calculate_E(B2, J, rho)
            get_curl_E(E, curl) 
            B1  -= 2 * dh * curl
            set_periodic_boundaries(B1)
        else:
            E, Ve, Te = calculate_E(B1, J, rho)
            get_curl_E(E, curl) 
            B2  -= 2 * dh * curl
            set_periodic_boundaries(B2)
            
    ## RESYNC FIELD COPIES ##
    if ii%2 == 0:
        E, Ve, Te = calculate_E(B2, J, rho)
        get_curl_E(E, curl) 
        B2  -= dh * curl
        set_periodic_boundaries(B2)
    else:
        E, Ve, Te = calculate_E(B1, J, rho)
        get_curl_E(E, curl) 
        B1  -= dh * curl
        set_periodic_boundaries(B1)

    ## AVERAGE FIELD SOLUTIONS: COULD PERFORM A CONVERGENCE TEST HERE IN FUTURE ##
    B1 += B2; B1 /= 2.0
    return


@nb.njit()
def calculate_E(B, J, qn):
    '''Calculates the value of the electric field based on source term and magnetic field contributions, assuming constant
    electron temperature across simulation grid. This is done via a reworking of Ampere's Law that assumes quasineutrality,
    and removes the requirement to calculate the electron current. Based on equation 10 of Buchner (2003, p. 140).
    INPUT:
        B   -- Magnetic field array. Displaced from E-field array by half a spatial step.
        J   -- Ion current density. Source term, based on particle velocities
        qn  -- Charge density. Source term, based on particle positions
    OUTPUT:
        E_out -- Updated electric field array
    '''
    curlB    = get_curl_B(B) / mu0
       
    Ve       = np.zeros((J.shape[0], 3)) 
    Ve[:, 0] = (J[:, 0] - curlB[:, 0]) / qn
    Ve[:, 1] = (J[:, 1] - curlB[:, 1]) / qn
    Ve[:, 2] = (J[:, 2] - curlB[:, 2]) / qn
    
    Te       = get_electron_temp(qn)
    del_p    = get_grad_P(qn, Te)
    
    B_center = interpolate_to_center_cspline3D(B)
    VexB     = cross_product(Ve, B_center)    

    E_out        = np.zeros((J.shape[0], 3))                 
    E_out[:, 0]  = - VexB[:, 0] - del_p / qn
    E_out[:, 1]  = - VexB[:, 1]
    E_out[:, 2]  = - VexB[:, 2]

    E_out       += e_resis * J

    E_out[0]                = E_out[J.shape[0] - 3]
    E_out[J.shape[0] - 2]   = E_out[1]
    E_out[J.shape[0] - 1]   = E_out[2]                                  # This doesn't really get used, but might as well
    return E_out, Ve, Te


#%% AUXILLIARY FUNCTIONS
@nb.njit()
def cross_product_single(A, B):
    '''
    Vector (cross) product between 3-vectors, A and B of same dimensions.

    INPUT:
        A, B -- 3-vectors (single values)

    OUTPUT:
        output -- The resultant cross product as a 3-vector
    '''
    output = np.zeros(A.shape)

    output[0] = A[1] * B[2] - A[2] * B[1]
    output[1] = A[2] * B[0] - A[0] * B[2]
    output[2] = A[0] * B[1] - A[1] * B[0]
    return output


@nb.njit()
def cross_product(A, B):
    '''
    Vector (cross) product between two vectors, A and B of same dimensions.

    INPUT:
        A, B -- 3D vectors (ndarrays)

    OUTPUT:
        output -- The resultant cross product with same dimensions as input vectors
    '''
    output = np.zeros(A.shape)

    for ii in np.arange(A.shape[0]):
        output[ii, 0] = A[ii, 1] * B[ii, 2] - A[ii, 2] * B[ii, 1]
        output[ii, 1] = A[ii, 2] * B[ii, 0] - A[ii, 0] * B[ii, 2]
        output[ii, 2] = A[ii, 0] * B[ii, 1] - A[ii, 1] * B[ii, 0]
    return output



@nb.njit()
def interpolate_to_center_cspline1D(arr):
    ''' 
    Used for interpolating values on the B-grid to the E-grid (for E-field calculation)
    1D array
    '''
    interp = np.zeros(arr.shape[0], dtype=np.float64)	
    
    for ii in range(1, arr.shape[0] - 2):                       
        interp[ii] = 0.5 * (arr[ii] + arr[ii + 1]) \
                 - 1./16 * (arr[ii + 2] - arr[ii + 1] - arr[ii] + arr[ii - 1])
         
    interp[0]                = interp[arr.shape[0] - 3]
    interp[arr.shape[0] - 2] = interp[1]
    interp[arr.shape[0] - 1] = interp[2]
    return interp


@nb.njit()
def interpolate_to_center_cspline3D(arr):
    ''' 
    Used for interpolating values on the B-grid to the E-grid (for E-field calculation)
    1D array
    '''
    dim    = arr.shape[1]
    interp = np.zeros((arr.shape[0], dim), dtype=np.float64)	

    for jj in range(dim):
        interp[:, jj] = interpolate_to_center_cspline1D(arr[:, jj])
    return interp


@nb.njit()
def interpolate_to_center_linear_1D(val):
    ''' 
    Interpolates vector cell edge values (i.e. B-grid quantities) to cell centers (i.e. E-grid quantities)
    Note: First and last (two) array values return zero due to ghost cell values
    '''
    center = np.zeros(val.shape)
    
    center[1:NX + 1] = 0.5*(val[1: NX + 1] + val[2:NX + 2])
        
    return center



#@nb.njit()
def check_timestep(qq, DT, pos, vel, Ie, W_elec, B, E, dns, max_inc, part_save_iter, field_save_iter, subcycles):
    max_Vx          = np.abs(vel[0, :]).max()
    max_V           = np.abs(vel      ).max()
    
    B_cent          = interpolate_to_center_cspline3D(B)
    B_tot           = np.sqrt(B_cent[:, 0] ** 2 + B_cent[:, 1] ** 2 + B_cent[:, 2] ** 2)
    high_rat        = qm_ratios.max()
    
    local_gyfreq    = high_rat  * np.abs(B_tot).max()      
    ion_ts          = orbit_res / local_gyfreq
    
    if E.max() != 0:
        elecfreq    = high_rat * (np.abs(E[:, 0] / max_V)).max()
        freq_ts     = freq_res / elecfreq                            
    else:
        freq_ts     = ion_ts
    
    vel_ts          = 0.75*dx / max_Vx
    DT_part         = min(freq_ts, vel_ts, ion_ts)
    
    # Reduce timestep
    change_flag       = 0
    if DT_part < 0.9*DT:
        position_update(pos, vel, Ie, W_elec, -0.5*DT)
        
        change_flag      = 1
        DT              *= 0.5
        max_inc         *= 2
        qq              *= 2
        part_save_iter  *= 2
        field_save_iter *= 2
        print('Timestep halved. Syncing particle velocity/position with DT =', DT)
    
    # Increase timestep (only if previously decreased, or everything's even - saves wonky cuts)
    elif DT_part >= 4.0*DT and qq%2 == 0 and part_save_iter%2 == 0 and field_save_iter%2 == 0 and max_inc%2 == 0:
        position_update(pos, vel, Ie, W_elec, -0.5*DT)
        
        change_flag       = 1
        DT               *= 2.0
        max_inc         //= 2
        qq              //= 2
        part_save_iter  //= 2
        field_save_iter //= 2
        
        print('Timestep doubled. Syncing particle velocity/position with DT =', DT)

    if adaptive_subcycling == 1:
        k_max           = np.pi / dx
        dispfreq        = (k_max ** 2) * (B_tot / (mu0 * dns)).max()             # Dispersion frequency
        dt_sc           = freq_res / dispfreq
        new_subcycles   = int(DT / dt_sc + 1)
        
        if subcycles < 0.75*new_subcycles:                                       
            subcycles *= 2
            print('Number of subcycles per timestep doubled to', subcycles)
            
        if subcycles > 3.0*new_subcycles and subcycles%2 == 0:                                      
            subcycles //= 2
            print('Number of subcycles per timestep halved to', subcycles)
            
        if subcycles >= 2000:
            subcycles = 2000
            sys.exit('Maximum number of subcycles reached :: Simulation aborted')

    return qq, DT, max_inc, part_save_iter, field_save_iter, change_flag, subcycles


#%% SAVE FUNCTIONS
def manage_directories():
    from shutil import rmtree
    print('Checking directories...')
    if (save_particles == 1 or save_fields == 1) == True:
        if os.path.exists('%s/%s' % (drive, save_path)) == False:
            os.makedirs('%s/%s' % (drive, save_path))                        # Create master test series directory
            print('Master directory created')

        path = ('%s/%s/run_%d' % (drive, save_path, run_num))          

        if os.path.exists(path) == False:
            os.makedirs(path)
            print('Run directory created')
        else:
            print('Run directory already exists')
            overwrite_flag = input('Overwrite? (Y/N) \n')
            if overwrite_flag.lower() == 'y':
                rmtree(path)
                os.makedirs(path)
            elif overwrite_flag.lower() == 'n':
                sys.exit('Program Terminated: Change run_num in simulation_parameters_1D')
            else:
                sys.exit('Unfamiliar input: Run terminated for safety')
    return


def store_run_parameters(dt, part_save_iter, field_save_iter, max_inc, max_time):
    import pickle
    d_path = '%s/%s/run_%d/data/' % (drive, save_path, run_num)     # Set main dir for data
    f_path = d_path + '/fields/'
    p_path = d_path + '/particles/'

    for folder in [d_path, f_path, p_path]:
        if os.path.exists(folder) == False:                               # Create data directories
            os.makedirs(folder)

    # Save simulation parameters to file (Some unused, copied from PREDCORR)
    params = dict([('seed', seed),
                   ('Nj', Nj),
                   ('dt', dt),
                   ('max_inc', max_inc),
                   ('max_time', max_time),
                   ('NX', NX),
                   ('ND', 0),
                   ('NC', NX+3),
                   ('N' , N),
                   ('dxm', dxm),
                   ('dx', dx),
                   ('L', 0.0),
                   ('B_eq', B0),
                   ('xmax', xmax),
                   ('xmin', xmin),
                   ('B_xmax', B0),
                   ('a', 0.0),
                   ('theta_xmax', 0.0),
                   ('theta_L', 0.0),
                   ('loss_cone', 0.0),
                   ('loss_cone_xmax', 0.0),
                   ('r_A', 0.0),
                   ('lat_A', 0.0),
                   ('B_A', 0.0),
                   ('rc_hwidth', 0.0),
                   ('ne', ne),
                   ('Te0', Te0),
                   ('ie', ie),
                   ('theta', theta),
                   ('part_save_iter', part_save_iter),
                   ('field_save_iter', field_save_iter),
                   ('max_wcinv', max_wcinv),
                   ('LH_frac', LH_frac),
                   ('freq_res', freq_res),
                   ('orbit_res', orbit_res),
                   ('run_desc', run_description),
                   ('method_type', 'CAM_CL_PARALLEL'),
                   ('particle_shape', 'TSC'),
                   ('field_periodic', 1),
                   ('run_time', None),
                   ('loop_time', None),
                   ('homogeneous', 1),
                   ('particle_periodic', 1),
                   ('particle_reflect', 0),
                   ('particle_reinit', 0),
                   ('disable_waves', 0),
                   ('source_smoothing', source_smoothing),
                   ('E_damping', 0),
                   ('quiet_start', quiet_start),
                   ('num_threads', nb.get_num_threads()),
                   ('subcycles', subcycles)
                   ])

    with open(d_path + 'simulation_parameters.pckl', 'wb') as f:
        pickle.dump(params, f)
        f.close()
        
    print('Simulation parameters saved')
    
    # Save particle parameters to file (Need to change things into vth)
    p_file = os.path.join(d_path, 'particle_parameters')
    np.savez(p_file, idx_start   = idx_start,
                     idx_end     = idx_end,
                     species_lbl = species_lbl,
                     temp_color  = temp_color,
                     temp_type   = temp_type,
                     dist_type   = dist_type,
                     mass        = mass,
                     charge      = charge,
                     drift_v     = drift_v,
                     nsp_ppc     = nsp_ppc,
                     N_species   = N_species,
                     density     = density,
                     vth_par     = vth_par,
                     vth_perp    = vth_perp,
                     Tpar        = Tpar,
                     Tperp       = Tperp,
                     Bc          = Bc,
                     Te0         = None)
    
    print('Particle parameters saved')
    return


def save_field_data(dt, field_save_iter, qq, Ji, E, B, Ve, Te, dns, sim_time):
    d_path = '%s/%s/run_%d/data/fields/' % (drive, save_path, run_num)
    r      = qq / field_save_iter

    d_fullpath = d_path + 'data%05d' % r
    
    np.savez(d_fullpath, E = E[:, 0:3], B = B[:, 0:3], Ji = Ji,
                         dns = dns, Ve = Ve[:, 0:3], Te = Te,
                         sim_time = sim_time,
                         damping_array  =np.zeros(B.shape[0]),
                         E_damping_array=np.zeros(E.shape[0]))
    return
    
    
def save_particle_data(dt, part_save_iter, qq, pos, vel, idx, sim_time):
    d_path = '%s/%s/run_%d/data/particles/' % (drive, save_path, run_num)
    r      = qq / part_save_iter

    d_filename = 'data%05d' % r
    d_fullpath = os.path.join(d_path, d_filename)
    np.savez(d_fullpath, pos=pos, vel=vel, idx=idx, sim_time = sim_time)
    return


def add_runtime_to_header(runtime):
    import pickle
    d_path = ('%s/%s/run_%d/data/' % (drive, save_path, run_num))     # Data path
    
    h_name = os.path.join(d_path, 'simulation_parameters.pckl')         # Header file path
    f      = open(h_name, 'rb')                                         # Open header file
    params = pickle.load(f)                                             # Load variables from header file into dict
    f.close()  
    
    params['run_time'] = runtime
    
    # Re-save
    with open(d_path + 'simulation_parameters.pckl', 'wb') as f:
        pickle.dump(params, f)
        f.close()
        print('Run time appended to simulation header file')
    return





#%% --- MAIN ---
if __name__ == '__main__':
    
    #################################
    ### FILENAMES AND DIRECTORIES ###
    #################################
    
    #### Read in command-line arguments, if present
    import argparse as ap
    parser = ap.ArgumentParser()
    parser.add_argument('-r', '--runfile'   , default='_run_params.run', type=str)
    parser.add_argument('-p', '--plasmafile', default='_plasma_params.plasma', type=str)
    parser.add_argument('-n', '--run_num'   , default=-1, type=int)
    args = vars(parser.parse_args())
    
    # Check root directory (change if on RCG)
    if os.name == 'posix':
        root_dir = os.path.dirname(sys.path[0])
    else:
        root_dir = '..'
        
    # Set input .run and .plasma files
    run_input    = root_dir +  '/run_inputs/' + args['runfile']
    plasma_input = root_dir +  '/run_inputs/' + args['plasmafile']
    
    
    
    ###########################
    ### LOAD RUN PARAMETERS ###
    ###########################
    with open(run_input, 'r') as f:
        drive             = f.readline().split()[1]        # Drive letter or path for portable HDD e.g. 'E:/' or '/media/yoshi/UNI_HD/'
        save_path         = f.readline().split()[1]        # Series save dir   : Folder containing all runs of a series
        run_num           = f.readline().split()[1]        # Series run number : For multiple runs (e.g. parameter studies) with same overall structure (i.e. test series)
    
        save_particles    = int(f.readline().split()[1])   # Save data flag    : For later analysis
        save_fields       = int(f.readline().split()[1])   # Save plot flag    : To ensure hybrid is solving correctly during run
        seed              = f.readline().split()[1]        # RNG Seed          : Set to enable consistent results for parameter studies
        
        homogenous        = int(f.readline().split()[1])   # Set B0 to homogenous (as test to compare to parabolic)
        particle_periodic = int(f.readline().split()[1])   # Set particle boundary conditions to periodic
        particle_reflect  = int(f.readline().split()[1])   # Set particle boundary conditions to reflective
        particle_reinit   = int(f.readline().split()[1])   # Set particle boundary conditions to reinitialize
        field_periodic    = int(f.readline().split()[1])   # Set field boundary to periodic (False: Absorbtive Boundary Conditions)
        disable_waves     = int(f.readline().split()[1])   # Zeroes electric field solution at each timestep
        source_smoothing  = int(f.readline().split()[1])   # Smooth source terms with 3-point Gaussian filter
        E_damping         = int(f.readline().split()[1])   # Damp E in a manner similar to B for ABCs
        quiet_start       = int(f.readline().split()[1])   # Flag to use quiet start (False :: semi-quiet start)
        damping_multiplier= float(f.readline().split()[1]) # Multiplies the r-factor to increase/decrease damping rate.
    
        NX        = int(f.readline().split()[1])           # Number of cells - doesn't include ghost cells
        ND        = int(f.readline().split()[1])           # Damping region length: Multiple of NX (on each side of simulation domain)
        max_wcinv = float(f.readline().split()[1])         # Simulation runtime, in multiples of the ion gyroperiod (in seconds)
        dxm       = float(f.readline().split()[1])         # Number of c/wpi per dx (Ion inertial length: anything less than 1 isn't "resolvable" by hybrid code, anything too much more than 1 does funky things to the waveform)
        
        ie        = int(f.readline().split()[1])           # Adiabatic electrons. 0: off (constant), 1: on.
        rc_hwidth = f.readline().split()[1]                # Ring current half-width in number of cells (2*hwidth gives total cells with RC) 
          
        orbit_res = float(f.readline().split()[1])         # Orbit resolution
        freq_res  = float(f.readline().split()[1])         # Frequency resolution     : Fraction of angular frequency for multiple cyclical values
        part_res  = float(f.readline().split()[1])         # Data capture resolution in gyroperiod fraction: Particle information
        field_res = float(f.readline().split()[1])         # Data capture resolution in gyroperiod fraction: Field information
    
        run_description = f.readline()                     # Commentary to attach to runs, helpful to have a quick description

    # Override because I keep forgetting to change this
    if os.name == 'posix':
        drive = '/home/c3134027/'

    # Set run number
    if args['run_num'] != -1:                              # Check CLI, or
        run_num = args['run_num']
    elif run_num != '-':                                       # Check input file, else
        run_num = int(run_num)
    else:                                                  # Autoset
        if os.path.exists(drive + save_path) == False:
            run_num = 0
        else:
            run_num = len(os.listdir(drive + save_path))
        print('Run number AUTOSET to ', run_num)
    
    if seed == '-':
        seed = None
    else:
        seed = int(seed)
    
    manage_directories()
    
    #######################################
    ### LOAD PARTICLE/PLASMA PARAMETERS ###
    #######################################
    with open(plasma_input, 'r') as f:
        species_lbl = np.array(f.readline().split()[1:])
        
        temp_color = np.array(f.readline().split()[1:])
        temp_type  = np.array(f.readline().split()[1:], dtype=int)
        dist_type  = np.array(f.readline().split()[1:], dtype=int)
        nsp_ppc    = np.array(f.readline().split()[1:], dtype=int)
        
        mass       = np.array(f.readline().split()[1:], dtype=float)
        charge     = np.array(f.readline().split()[1:], dtype=float)
        drift_v    = np.array(f.readline().split()[1:], dtype=float)
        density    = np.array(f.readline().split()[1:], dtype=float)*1e6
        anisotropy = np.array(f.readline().split()[1:], dtype=float)
                                           
        E_perp     = np.array(f.readline().split()[1:], dtype=float)
        E_e        = float(f.readline().split()[1])
        beta_flag  = int(f.readline().split()[1])
    
        L         = float(f.readline().split()[1])           # Field line L shell
        B_eq      = f.readline().split()[1]                  # Initial magnetic field at equator: None for L-determined value (in T) :: 'Exact' value in node ND + NX//2
        B_xmax_ovr= f.readline().split()[1]

    # Misc softish-coded stuff    
    min_dens            = 0.05                               # Allowable minimum charge density in a cell, as a fraction of ne*q
    adaptive_timestep   = 1                                  # Flag (True/False) for adaptive timestep based on particle and field parameters
    adaptive_subcycling = 1                                  # Flag (True/False) to adaptively change number of subcycles during run to account for high-frequency dispersion
    subcycles           = 12                                 # Number of field subcycling steps for Cyclic Leapfrog

    B0        = float(B_eq)                                  # Unform initial magnetic field value (in T)
    ne        = (density * charge).sum()                     # Electron density (in /m3, same as total ion density (for singly charged ions))
    theta     = 0.0
    
    
    ### -- Normalization of density override (e.g. Fu, Winkse)
    rat        = 5
    ne         = (rat*B0)**2 * e0 / me # REMOVE
    density    = np.array([0.05, 0.94, 0.01])*ne  # REMOVE
    ### --- DELETE LATER
    
    

#%%### DERIVED SIMULATION PARAMETERS
    E_par     = E_perp / (anisotropy + 1) 
    charge    *= q                                           # Cast species charge to Coulomb
    mass      *= mp                                          # Cast species mass to kg

    # Particle energy: If beta == 1, energies are in beta. If not, they are in eV 
    if beta_flag == 1:
        Te0    = B0 ** 2 * E_e    / (2 * mu0 * ne * kB)      # Temperatures of each species in Kelvin
        Tpar   = B0 ** 2 * E_par  / (2 * mu0 * ne * kB)
        Tperp  = B0 ** 2 * E_perp / (2 * mu0 * ne * kB)
        
        kbt_par    = E_par  * (B0 ** 2) / (2 * mu0 * ne)
        kbt_per    = E_perp * (B0 ** 2) / (2 * mu0 * ne)
        vth_perp   = np.sqrt(kbt_per /  mass)                # Perpendicular thermal velocities
        vth_par    = np.sqrt(kbt_par /  mass)                # Parallel thermal velocities
    else:
        Te0        = E_e    * 11603.
        Tpar       = E_par  * 11603.
        Tperp      = E_perp * 11603.
        
        vth_perp   = np.sqrt(charge *  E_perp /  mass)    # Perpendicular thermal velocities
        vth_par    = np.sqrt(charge *  E_par  /  mass)    # Parallel thermal velocities
    
    vth_perp   = np.sqrt(charge *  E_perp /  mass)    # Perpendicular thermal velocities
    vth_par    = np.sqrt(charge *  E_par  /  mass)    # Parallel thermal velocities
    
    wpi        = np.sqrt(ne * q ** 2 / (mp * e0))            # Proton   Plasma Frequency, wpi (rad/s)
    wpe        = np.sqrt(ne * q ** 2 / (me * e0))            # Proton   Plasma Frequency, wpi (rad/s)
    va         = B0 / np.sqrt(mu0*ne*mp)                     # Alfven speed: Assuming pure proton plasma
    
    qm_ratios  = np.divide(charge, mass)
    gyfreq     = q*B0/mp                                     # Proton   Gyrofrequency (rad/s) (since this will be the highest of all ion species)
    e_gyfreq   = q*B0/me                                     # Electron Gyrofrequency (rad/s)

    dx         = dxm * va / gyfreq                           # Alternate method of calculating dx (better for multicomponent plasmas)
    dx2        = dxm * c / wpi                               # Spatial cadence, based on ion inertial length
    xmin       = 0.0                                         # Minimum simulation dimension
    xmax       = NX * dx                                     # Maximum simulation dimension
    size       = NX + 3                                      # Field array size
    N          = nsp_ppc.sum()*NX                            # Number of Particles to simulate: # cells x # particles per cell, excluding ghost cells
    
    drift_v   *= va                                          # Cast species velocity to m/s
    
    Nj         = len(mass)                                   # Number of species
    N_species  = NX * nsp_ppc                                # Number of sim particles for each species, total
    n_contr    = density / nsp_ppc                           # Species density contribution: Each macroparticle contributes this density to a cell

    idx_start  = np.asarray([np.sum(N_species[0:ii]    )     for ii in range(0, Nj)])    # Start index values for each species in order
    idx_end    = np.asarray([np.sum(N_species[0:ii + 1])     for ii in range(0, Nj)])    # End   index values for each species in order
    
    k_max      = np.pi / dx                                  # Maximum permissible wavenumber in system (SI???)
    
    LH_frac    = 0.0                                         # Fraction of Lower Hybrid resonance: 
                                                             # Used to calculate electron resistivity by setting "anomalous"
                                                             # electron/ion collision as some multiple of the LHF. 0 disables e_resis.
    LH_res_is  = 1. / (gyfreq * e_gyfreq) + 1. / wpi ** 2    # Lower Hybrid Resonance frequency, inverse squared
    LH_res     = 1. / np.sqrt(LH_res_is)                     # Lower Hybrid Resonance frequency: DID I CHECK THIS???
    
    e_resis     = (LH_frac * LH_res)  / (e0 * wpe ** 2)      # Electron resistivity (using intial conditions for wpi/wpe)
    speed_ratio = c / va
    
    Bc       = np.zeros((size, 3), dtype=np.float64)
    Bc[:, 0] = B0 * np.cos(theta * np.pi / 180.)      # Set Bx initial
    Bc[:, 1] = 0.                                     # Set By initial
    Bc[:, 2] = B0 * np.sin(theta * np.pi / 180.)      # Set Bz initial
    
    print('Run Started')
    print('Run Series         : {}'.format(save_path.split('//')[-1]))
    print('Run Number         : {}'.format(run_num))
    print('Field save flag    : {}'.format(save_fields))
    print('Particle save flag : {}\n'.format(save_particles))
    
    print('Sim domain length  : {:5.2f}R_E'.format(2 * xmax / RE))
    print('Density            : {:5.2f}cc'.format(ne / 1e6))
    print('Uniform B-field    : {:5.2f}nT'.format(B0*1e9))

    print('Equat. Gyroperiod: : {}s'.format(round(2. * np.pi / gyfreq, 3)))
    print('Inverse rad gyfreq : {}s'.format(round(1 / gyfreq, 3)))
    print('Maximum sim time   : {}s ({} gyroperiods)\n'.format(round(max_wcinv /  gyfreq, 2), 
                                                               round(max_wcinv/(2*np.pi), 2)))
    
    print('{} cells'.format(NX))
    print('{} particles total\n'.format(N))
    
    #%% BEGIN HYBRID
    start_time = timer()
    
    # Initialize arrays and initial conditions
    Ie       = np.zeros(N,      dtype=np.uint16)
    Ib       = np.zeros(N,      dtype=np.uint16)
    W_elec   = np.zeros((3, N), dtype=np.float64)
    W_mag    = np.zeros((3, N), dtype=np.float64)
    
    ni       = np.zeros((size, Nj), dtype=np.float64)
    ni_init  = np.zeros((size, Nj), dtype=np.float64)
    
    nu_init  = np.zeros((size, Nj, 3), dtype=np.float64)
    nu_plus  = np.zeros((size, Nj, 3), dtype=np.float64)
    nu_minus = np.zeros((size, Nj, 3), dtype=np.float64)
    
    rho_half = np.zeros(size, dtype=np.float64)
    rho_int  = np.zeros(size, dtype=np.float64)
    
    J        = np.zeros((size, 3), dtype=np.float64)
    J_plus   = np.zeros((size, 3), dtype=np.float64)
    J_minus  = np.zeros((size, 3), dtype=np.float64)
    L        = np.zeros( size,     dtype=np.float64)
    G        = np.zeros((size, 3), dtype=np.float64)
    
    B        = np.zeros((size, 3), dtype=np.float64)
    B2       = np.zeros((size, 3), dtype=np.float64)
    E        = np.zeros((size, 3), dtype=np.float64)
    Ve       = np.zeros((size, 3), dtype=np.float64)
    Te       = np.zeros((size   ), dtype=np.float64)

    temp3d   = np.zeros((size, 3), dtype=np.float64)

    if quiet_start == 0:
        pos, idx = uniform_distribution()
        vel      = gaussian_distribution()
    else:
        pos, vel, idx = init_quiet_start()

    B[:, 0]  = Bc[:, 0].copy()      # Set Bx initial
    B[:, 1]  = Bc[:, 1].copy()      # Set By initial
    B[:, 2]  = Bc[:, 2].copy()      # Set Bz initial
    
    assign_weighting_TSC(pos, Ie, W_elec)

    DT, max_inc, part_save_iter, field_save_iter, subcycles = set_timestep(vel)

    print('Loading initial state...\n')
    init_collect_moments(pos, vel, Ie, W_elec, idx, ni_init, nu_init, ni, nu_plus, 
                         rho_int, rho_half, J, J_plus, L, G, 0.5*DT)

    
    # Put init into qq = 0 and save as usual, qq = 1 will be at t = dt
    qq      = 0; sim_time = 0.0
    print('Starting loop...')
    while qq < max_inc:
        ############################
        ##### EXAMINE TIMESTEP #####
        ############################
        if adaptive_timestep == 1:
            qq, DT, max_inc, part_save_iter, field_save_iter, change_flag, subcycles =\
                check_timestep(qq, DT, pos, vel, Ie, W_elec, B, E, rho_int, max_inc, part_save_iter, field_save_iter, subcycles)
    
            # Collect new moments and desync position and velocity
            if change_flag == 1:
                init_collect_moments(pos, vel, Ie, W_elec, idx, ni_init, nu_init, ni, nu_plus, 
                         rho_int, rho_half, J, J_plus, L, G, 0.5*DT)

        
        #######################
        ###### MAIN LOOP ######
        #######################
        cyclic_leapfrog(B, B2, rho_int, J, temp3d, DT, subcycles)
        E, Ve, Te = calculate_E(B, J, rho_half)

        push_current(J_plus, J, E, B, L, G, DT)
        E, Ve, Te = calculate_E(B, J, rho_half)
        
        assign_weighting_TSC(pos, Ib, W_mag, E_nodes=False)
        velocity_update(pos, vel, Ie, W_elec, Ib, W_mag, idx, B, E, DT)

        # Store pc(1/2) here while pc(3/2) is collected
        rho_int[:]  = rho_half[:] 
        collect_moments(pos, vel, Ie, W_elec, idx, ni, nu_plus, nu_minus, 
                                             rho_half, J_minus, J_plus, L, G, DT)
        
        rho_int += rho_half
        rho_int /= 2.0
        J        = 0.5 * (J_plus  +  J_minus)

        cyclic_leapfrog(B, B2, rho_int, J, temp3d, DT, subcycles)
        E, Ve, Te   = calculate_E(B, J, rho_int)

        ########################
        ##### OUTPUT DATA  #####
        ########################
        if qq%part_save_iter == 0 and save_particles == 1:
            save_particle_data(DT, part_save_iter, qq, pos, vel, idx, sim_time)

        if qq%field_save_iter == 0 and save_fields == 1:
            save_field_data(DT, field_save_iter, qq, J, E, B, Ve, Te, rho_int, sim_time)
        
        if qq%50 == 0:
            running_time = int(timer() - start_time)
            hrs          = running_time // 3600
            rem          = running_time %  3600
            
            mins         = rem // 60
            sec          = rem %  60
            
            print('Step {} of {} :: Current runtime {:02}:{:02}:{:02}'.format(qq, max_inc, hrs, mins, sec))

        qq        += 1
        sim_time  += DT
        
    runtime = round(timer() - start_time,2) 
    print('Run complete : {} s'.format(runtime))
    if save_fields == 1 or save_particles == 1:
        add_runtime_to_header(runtime)
        fin_path = '%s/%s/run_%d/run_finished.txt' % (drive, save_path, run_num)
        with open(fin_path, 'w') as open_file:
            pass